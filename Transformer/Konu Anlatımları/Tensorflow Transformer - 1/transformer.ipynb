{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03ecbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow ve Keras temel modÃ¼lleri\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Dense,\n",
    "    Embedding,\n",
    "    MultiHeadAttention,\n",
    "    LayerNormalization,\n",
    "    Dropout\n",
    ")\n",
    "\n",
    "# EÄŸitim iÃ§in\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "# Veri hazÄ±rlama\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# YardÄ±mcÄ± kÃ¼tÃ¼phaneler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182d9924",
   "metadata": {},
   "source": [
    "# ğŸ“˜ TRANSFORMER MÄ°MARÄ°SÄ°NE GÄ°RÄ°Å â€“ KONU BAÅLIKLARI VE AÃ‡IKLAMALARI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a533ae9",
   "metadata": {},
   "source": [
    "## 1. ğŸ” Transformer Nedir?\n",
    "* LSTM/RNN gibi sÄ±ralÄ± yapÄ±lara alternatif olarak geliÅŸtirilmiÅŸtir.\n",
    "\n",
    "* 2017â€™de â€œAttention is All You Needâ€ makalesiyle tanÄ±tÄ±lmÄ±ÅŸtÄ±r.\n",
    "\n",
    "* DoÄŸal dil iÅŸleme (NLP), gÃ¶rÃ¼ntÃ¼ iÅŸleme, zaman serisi ve Ã§ok daha fazlasÄ±nda kullanÄ±labilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b171e75b",
   "metadata": {},
   "source": [
    "## 2. ğŸ§  Self-Attention MekanizmasÄ±\n",
    "Her kelime, diÄŸer kelimelerle olan iliÅŸkisini deÄŸerlendirir.\n",
    "\n",
    "* Query, Key, Value matrisleri Ã¼zerinden hesaplanÄ±r.\n",
    "\n",
    "Uzun dizilerdeki baÄŸlam iliÅŸkilerini Ã§ok daha etkili ÅŸekilde Ã¶ÄŸrenir.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca071ec",
   "metadata": {},
   "source": [
    "## 3. ğŸ§© Multi-Head Attention\n",
    "* Self-Attention iÅŸlemi birden fazla â€œbaÅŸâ€ ile yapÄ±lÄ±r.\n",
    "\n",
    "* FarklÄ± temsillerin paralel olarak Ã¶ÄŸrenilmesini saÄŸlar.\n",
    "\n",
    "* Her baÅŸ, farklÄ± bir bilgiye odaklanabilir (Ã¶rneÄŸin dilbilgisi, baÄŸlam, kelime iliÅŸkisi)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6106e885",
   "metadata": {},
   "source": [
    "## 4. ğŸŒ Positional Encoding\n",
    "* Transformer'lar sÄ±ralÄ± bilgiye doÄŸrudan sahip deÄŸildir.\n",
    "\n",
    "* Pozisyon bilgisini sinÃ¼soidal fonksiyonlarla modele enjekte eder.\n",
    "\n",
    "* Her kelimenin cÃ¼mle iÃ§indeki konumu bÃ¶ylece anlaÅŸÄ±lÄ±r hale gelir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1aed51",
   "metadata": {},
   "source": [
    "## 5. ğŸ§± Transformer BloklarÄ±nÄ±n YapÄ±sÄ±\n",
    "Her Encoder/Decoder bloÄŸu ÅŸu bileÅŸenleri iÃ§erir:\n",
    "\n",
    "* Multi-Head Attention\n",
    "\n",
    "* Add & Layer Normalization\n",
    "\n",
    "* Feedforward Neural Network\n",
    "\n",
    "* Add & Layer Normalization\n",
    "\n",
    "Her blokta residual baÄŸlantÄ±lar vardÄ±r (skip connections), eÄŸitim sÃ¼recini stabil tutar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373e97b1",
   "metadata": {},
   "source": [
    "## 6. ğŸ” Encoder ve Decoder YapÄ±sÄ±\n",
    "Encoder:\n",
    "\n",
    "* GiriÅŸ cÃ¼mlesini iÅŸler, gizli temsiller Ã¼retir.\n",
    "\n",
    "Decoder:\n",
    "\n",
    "* Bu temsillerden yola Ã§Ä±karak Ã§Ä±kÄ±ÅŸ dizisi Ã¼retir.\n",
    "\n",
    "Masked Attention ile gelecekteki kelimelere bakmayÄ± engeller (Ã¶rneÄŸin Ã§eviride)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1ac948",
   "metadata": {},
   "source": [
    "## 7. âš™ï¸ Transformerâ€™Ä±n AvantajlarÄ±\n",
    "* Paralel iÅŸlemeye uygun (GPU/TPU iÃ§in hÄ±zlÄ±).\n",
    "\n",
    "* Uzun baÄŸÄ±mlÄ±lÄ±klarÄ± daha iyi Ã¶ÄŸrenir.\n",
    "\n",
    "* Daha az bellekle daha fazla baÄŸlam yakalayabilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2cb323",
   "metadata": {},
   "source": [
    "## 8. ğŸ› ï¸ Transformer ile Uygulama SenaryolarÄ±\n",
    "* Makine Ã§evirisi (EN â†’ TR)\n",
    "\n",
    "* Chatbotlar (GPT mimarisi)\n",
    "\n",
    "* Metin sÄ±nÄ±flandÄ±rma (BERT gibi)\n",
    "\n",
    "* Metin tamamlama / Ã¼retim (GPT-2, GPT-3)\n",
    "\n",
    "* Zaman serisi tahmini, gÃ¶rÃ¼ntÃ¼ iÅŸlemede ViT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb69be55",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12748a2",
   "metadata": {},
   "source": [
    "# SEQ2SEQ ile TRANSFORMER arasÄ±ndaki farklar nelerdir ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9074e046",
   "metadata": {},
   "source": [
    "### ğŸ’¡ 1. Veri Ä°ÅŸleme YÃ¶ntemi (SÄ±ralÄ± mÄ±? Paralel mi?)\n",
    "* LSTM tabanlÄ± modeller veriyi sÄ±rayla iÅŸler. Her adÄ±mda bir kelime alÄ±nÄ±r, Ã¶nceki gizli durum aktarÄ±lÄ±r. Bu nedenle hesaplama zaman baÄŸÄ±mlÄ± ve sÄ±ralÄ±dÄ±r.\n",
    "\n",
    "* Transformer ise tÃ¼m kelimeleri aynÄ± anda iÅŸler. Ã‡Ã¼nkÃ¼ self-attention tÃ¼m diziyi bir kerede gÃ¶rebilir. Bu sayede eÄŸitim sÃ¼reci Ã§ok daha hÄ±zlÄ±dÄ±r ve paralel hesaplama yapÄ±labilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e5b1e1",
   "metadata": {},
   "source": [
    "\n",
    "### ğŸ§  2. Uzun BaÄŸlamlarÄ± Ã–ÄŸrenme YeteneÄŸi\n",
    "* LSTMâ€™ler uzun cÃ¼mlelerde erken gelen kelimeleri unutabilir. Evet, bidirectional LSTM ve attention eklenerek bu kÄ±smen iyileÅŸtirilir ama tam Ã§Ã¶zÃ¼m deÄŸildir.\n",
    "\n",
    "* Transformer, her kelimenin diÄŸer tÃ¼m kelimelerle olan iliÅŸkisini self-attention ile doÄŸrudan Ã¶ÄŸrenir. Bu sayede uzun baÄŸlamlar Ã§ok daha saÄŸlam Ã¶ÄŸrenilir.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7b7ef0",
   "metadata": {},
   "source": [
    "### ğŸ§² 3. Attention KullanÄ±mÄ±\n",
    "* LSTM tabanlÄ± modellerde Attention genellikle Encoderâ€™Ä±n son gizli durumuna gÃ¶re Ã§alÄ±ÅŸÄ±r ve Decoder'da dÄ±ÅŸtan eklenir.\n",
    "\n",
    "* Transformer'da ise Attention modelin merkezi parÃ§asÄ±dÄ±r. Hem Encoder hem Decoder Ã§ok katmanlÄ± Attention bloklarÄ±ndan oluÅŸur. Yani attention kenarda bir eklenti deÄŸil, doÄŸrudan yapÄ±nÄ±n kendisidir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e009efee",
   "metadata": {},
   "source": [
    "### ğŸ§± 4. YapÄ±sal Fark (Layer BazÄ±nda)\n",
    "* LSTM modeller katman katman ilerlese de her katman kendi iÃ§inde sÄ±ralÄ± bilgi taÅŸÄ±r. Layerâ€™lar arasÄ±nda veri genellikle bir hidden state olarak geÃ§er.\n",
    "\n",
    "Transformerâ€™da her katman:\n",
    "\n",
    "* Multi-Head Attention\n",
    "\n",
    "* Residual Connection\n",
    "\n",
    "* Layer Normalization\n",
    "\n",
    "* Feedforward katman iÃ§erir.\n",
    "\n",
    "Bu yapÄ± sayesinde Ã§ok daha derin modeller stabil ÅŸekilde eÄŸitilebilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f042b7",
   "metadata": {},
   "source": [
    "### âœ… Ã–zetle Neden Transformer?\n",
    "* LSTM'ler sÄ±ralÄ± ve yavaÅŸ, Transformer paralel ve hÄ±zlÄ±.\n",
    "\n",
    "* Transformer, daha uzun baÄŸlamlarÄ± etkili biÃ§imde Ã¶ÄŸrenebilir.\n",
    "\n",
    "* Attention, LSTM'de sonradan eklenir ama Transformer'da yapÄ±nÄ±n kalbidir.\n",
    "\n",
    "* EÄŸitimde verimli, Ã¶lÃ§eklenebilir ve daha derin mimarilere uygundur.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e106db3b",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85d41f7",
   "metadata": {},
   "source": [
    "# ğŸ§¾  Frame TabanlÄ± Transformer Sohbet Modeli\n",
    "### ğŸ“Œ GiriÅŸ\n",
    "* Bu Ã§alÄ±ÅŸmada, Transformer Encoder-Decoder mimarisi kullanÄ±larak geliÅŸtirilen frame tabanlÄ± bir sohbet modeli eÄŸitilecektir. Bu model, kullanÄ±cÄ±dan gelen belirli kalÄ±plardaki (frame) girdilere karÅŸÄ±lÄ±k olarak Ã¶nceden tanÄ±mlanmÄ±ÅŸ Ã§Ä±ktÄ±larÄ± Ã¶ÄŸrenmeyi amaÃ§lar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b5ffd9",
   "metadata": {},
   "source": [
    "### ğŸ” AmaÃ§\n",
    "* Bu modelin amacÄ±, Ã§ok bÃ¼yÃ¼k dil modelleri (Ã¶rneÄŸin GPT-2, GPT-3) gibi genel amaÃ§lÄ± bir dil zekasÄ± Ã¼retmek deÄŸil; sadece eÄŸitim sÄ±rasÄ±nda verilen input-output Ã§iftleri Ã¼zerinden Ã¶ÄŸrenerek, sÄ±nÄ±rlÄ± bir etkileÅŸim saÄŸlamaktÄ±r."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82949c1",
   "metadata": {},
   "source": [
    "### ğŸ§  Model Ã–zellikleri\n",
    "* Mimari: Transformer Encoderâ€“Decoder (Attention temelli)\n",
    "\n",
    "* EÄŸitim verisi: Girdiâ€“Ã§Ä±ktÄ± Ã§iftlerinden oluÅŸan kÃ¼Ã§Ã¼k bir Ã¶zel veri kÃ¼mesi\n",
    "\n",
    "* Ã‡alÄ±ÅŸma mantÄ±ÄŸÄ±: KullanÄ±cÄ±dan gelen belirli cÃ¼mleleri tanÄ±yÄ±p, karÅŸÄ±lÄ±k gelen Ã§Ä±ktÄ±yÄ± Ã¼retmek\n",
    "\n",
    "* Genelleme kabiliyeti: DÃ¼ÅŸÃ¼ktÃ¼r, sadece Ã¶rneklerine benzer girdilere anlamlÄ± cevap verir\n",
    "\n",
    "* AvantajÄ±: KÃ¼Ã§Ã¼k veriyle Ã§alÄ±ÅŸabilir, hÄ±zlÄ± eÄŸitilir\n",
    "\n",
    "* DezavantajÄ±: Ezberci davranÄ±r; eÄŸitim dÄ±ÅŸÄ±ndaki Ã¶rÃ¼ntÃ¼lerde baÅŸarÄ±sÄ± dÃ¼ÅŸer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97df054",
   "metadata": {},
   "source": [
    "### ğŸ“š Uygulama AlanÄ±\n",
    "* MenÃ¼ tabanlÄ± chatbot\n",
    "\n",
    "* SÄ±k sorulan sorular yanÄ±tlayÄ±cÄ±sÄ± (FAQ bot)\n",
    "\n",
    "* KapalÄ± alan asistanlarÄ± (Ã¶rneÄŸin: otel resepsiyonu, otomatik mÃ¼ÅŸteri temsilcisi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9976a737",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415acc4d",
   "metadata": {},
   "source": [
    "### Åimdi sizinle frame tabanlÄ± Transformer mantÄ±ÄŸÄ±nÄ± inceyeleyelim.Bu adÄ±mda kendi oluÅŸturduÄŸum verisetini kullanacaÄŸÄ±z.AdÄ±mlarÄ± tek tek aÃ§Ä±klayarak devam edeceÄŸiz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f8f322",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77857e0",
   "metadata": {},
   "source": [
    "# -- Frame TabanlÄ± Transformerlar -- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e9feb4",
   "metadata": {},
   "source": [
    "* BU NOTEBOOK ANLATIMINDA RNN SEQ2SEQ MODELLERÄ°N , RNN'LERÄ°N , ANN'LERÄ°N , CNN'LERÄ°N BÄ°LÄ°NDÄ°ÄÄ° VAR SAYILMIÅTIR.ANLATIMLAR DÄ°ÄER REPOLARIN DEVAMI OLARAK SUNULACAKTIR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba97ede",
   "metadata": {},
   "source": [
    "### ğŸ§© Frame TabanlÄ± Transformer Modeli â€“ AdÄ±m AdÄ±m Plan\n",
    "\n",
    "2ï¸âƒ£ ğŸ“Š Veriyi pandas ile oku (pd.read_csv)\n",
    "\n",
    "3ï¸âƒ£ ğŸ“ CÃ¼mleleri listeye al (input ve output ayrÄ± ayrÄ±)\n",
    "\n",
    "4ï¸âƒ£ ğŸ”¤ Tokenizer oluÅŸtur (hem input hem output iÃ§in)\n",
    "\n",
    "5ï¸âƒ£ ğŸ“ CÃ¼mleleri tokenize et, pad uygula (maksimum uzunluk belirle)\n",
    "\n",
    "6ï¸âƒ£ ğŸ“¦ Veriyi ayÄ±r â†’ X, y_input, y_target (encoder/decoder ayrÄ±mÄ±)\n",
    "\n",
    "7ï¸âƒ£ ğŸ—ï¸ Transformer modelini kur (Encoderâ€“Decoder yapÄ±sÄ±)\n",
    "\n",
    "8ï¸âƒ£ âš™ï¸ Loss ve optimizer tanÄ±mla (Ã¶rneÄŸin SparseCategoricalCrossentropy)\n",
    "\n",
    "9ï¸âƒ£ ğŸ¯ Modeli eÄŸit (model.fit)\n",
    "\n",
    "ğŸ”Ÿ ğŸ’¬ Tahmin fonksiyonu yaz (input ver, output Ã¼ret)\n",
    "\n",
    "1ï¸âƒ£1ï¸âƒ£ ğŸ§ª Modeli test et (Ã¶rnek girdilerle dene)\n",
    "\n",
    "1ï¸âƒ£2ï¸âƒ£ ğŸ’¾ Modeli kaydet (isteÄŸe baÄŸlÄ± olarak model.save())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1513aca",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dd06a6",
   "metadata": {},
   "source": [
    "##  ğŸ“Š Veriyi pandas ile oku (pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bda9eec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 input                                             output\n",
      "0              Merhaba           Merhaba, size nasÄ±l yardÄ±mcÄ± olabilirim?\n",
      "1            NasÄ±lsÄ±n?           Ä°yiyim, teÅŸekkÃ¼r ederim. Siz nasÄ±lsÄ±nÄ±z?\n",
      "2             AdÄ±n ne?  Ben bir yapay zekÃ¢ asistanÄ±yÄ±m. AdÄ±m yok ama y...\n",
      "3      KaÃ§ yaÅŸÄ±ndasÄ±n?                        Benim yaÅŸÄ±m yok, dijitalim!\n",
      "4  BugÃ¼n gÃ¼nlerden ne?  Maalesef tarih bilgim yok, ama sistem saatinde...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\hdgn5\\OneDrive\\MasaÃ¼stÃ¼\\Transformerlar\\Konu AnlatÄ±mlarÄ±\\Tenserflow Transformer - Teorik\\Ã¶rnek_set.csv\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26cb1c6",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89389344",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ ğŸ“ CÃ¼mleleri listeye al (input ve output ayrÄ± ayrÄ±)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bd32f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = df['input'].astype(str).to_list()\n",
    "target_texts = df['output'].astype(str).to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a1b9e6",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc239a7b",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ ğŸ”¤ Tokenizer oluÅŸtur (hem input hem output iÃ§in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900f7762",
   "metadata": {},
   "source": [
    "* AslÄ±nda seq2seq modellerde kullandÄ±ÄŸÄ±mÄ±zdan Ã§ok daha farklÄ± bir iÅŸlem yapmayacaÄŸÄ±z.Neredeyse aynÄ± bile denebilir.ÃœstÃ¼ne daha iyi hale getirmek iÃ§in eklentiler aÃ§acaÄŸÄ±m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c081932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# START VE END TOKENLARINI CÃœMLEYE EKLEDÄ°K\n",
    "target_texts_with_token = ['<start> ' + t + ' <end>' for t in target_texts]\n",
    "\n",
    "# TOKENIZERLARI FÄ°LTRE VE OOV TOKEN Ä°LE OLUÅTURDUK\n",
    "input_tokenizer = Tokenizer(filters=\"\",oov_token=\"<OOV>\")\n",
    "target_tokenizer = Tokenizer(filters=\"\",oov_token=\"<OOV>\")\n",
    "\n",
    "# TOKENLARI FÄ°T ETTÄ°K\n",
    "input_tokenizer.fit_on_texts(input_texts)\n",
    "target_tokenizer.fit_on_texts(target_texts_with_token)\n",
    "\n",
    "# CÃœMLELERÄ° TOKENÄ°ZE EDECEÄÄ°Z\n",
    "input_sequences = input_tokenizer.texts_to_sequences(input_texts)\n",
    "\n",
    "decoder_input_sequences = target_tokenizer.texts_to_sequences(['<start> ' + t for t in target_texts])\n",
    "\n",
    "decoder_target_sequences = target_tokenizer.texts_to_sequences([t+' <end>' for t in target_texts])\n",
    "\n",
    "# MAX UZUNLUÄU HESAPLADIK\n",
    "max_input_len = max(len(seq) for seq in input_sequences)\n",
    "max_output_len = max(len(seq) for seq in input_sequences)\n",
    "\n",
    "max_len = max(max_input_len,max_output_len)\n",
    "\n",
    "# PAD Ä°ÅLEMÄ°NÄ° GERÃ‡EKLEÅTÄ°RDÄ°K\n",
    "encoder_input = pad_sequences(input_sequences,maxlen=max_len,padding=\"post\")\n",
    "decoder_input = pad_sequences(decoder_input_sequences,maxlen=max_len,padding=\"post\")\n",
    "decoder_target = pad_sequences(decoder_target_sequences,maxlen=max_len,padding=\"post\")  \n",
    "\n",
    "# VOCAB_SÄ°ZE BELÄ°RLEDÄ°K.\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "target_vocab_size = len(target_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a80d417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "249\n"
     ]
    }
   ],
   "source": [
    "print(input_vocab_size)\n",
    "print(target_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4273b279",
   "metadata": {},
   "source": [
    "### Bu iÅŸlemleri daha iyi bir hale getirebiliriz.Mesela verileri temizleriz ya da Ã¶zel tokenlarÄ± elle ekleriz.Gelin bu halden daha iyi bir hale getirelim bu tokenizerlarÄ±."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75e71a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "### ğŸ”¤ 1. Ã–zel tokenlarÄ± tanÄ±mla\n",
    "SPECIAL_TOKENS = ['<pad>', '<start>', '<end>', '<OOV>']\n",
    "\n",
    "### ğŸ§¹ 2. Temizlik fonksiyonu\n",
    "def clean_text(text):\n",
    "    text = text.lower().strip()\n",
    "    text = text.replace(\"â€™\", \"'\").replace(\"â€œ\", '\"').replace(\"â€\", '\"')\n",
    "    text = text.replace(\"â€“\", \"-\").replace(\"...\", \".\")\n",
    "    return text\n",
    "\n",
    "### ğŸ“ 3. CÃ¼mleleri temizle\n",
    "input_texts_clean = [clean_text(t) for t in input_texts]\n",
    "target_texts_clean = [clean_text(t) for t in target_texts]\n",
    "\n",
    "### ğŸª„ 4. Target cÃ¼mlelere start ve end token ekle\n",
    "target_texts_with_tokens = ['<start> ' + t + ' <end>' for t in target_texts_clean]\n",
    "\n",
    "### ğŸ§  5. Tokenizer oluÅŸtur ve Ã¶zel tokenlarÄ± vocab'a enjekte et\n",
    "def build_tokenizer(texts, num_words=None):\n",
    "    tokenizer = Tokenizer(filters='', oov_token='<OOV>', num_words=num_words)\n",
    "    tokenizer.fit_on_texts(SPECIAL_TOKENS + texts)  # Ã¶zel tokenlarÄ± ilk sÄ±raya ekle\n",
    "    return tokenizer\n",
    "\n",
    "input_tokenizer = build_tokenizer(input_texts_clean)\n",
    "target_tokenizer = build_tokenizer(target_texts_with_tokens)\n",
    "\n",
    "### ğŸ”¢ 6. CÃ¼mleleri tokenize et\n",
    "input_sequences = input_tokenizer.texts_to_sequences(input_texts_clean)\n",
    "decoder_input_sequences = target_tokenizer.texts_to_sequences(\n",
    "    ['<start> ' + t for t in target_texts_clean]\n",
    ")\n",
    "decoder_target_sequences = target_tokenizer.texts_to_sequences(\n",
    "    [t + ' <end>' for t in target_texts_clean]\n",
    ")\n",
    "\n",
    "### ğŸ“ 7. Maksimum uzunluk belirle (tek max_len kullanÄ±lacak)\n",
    "max_input_len = max(len(seq) for seq in input_sequences)\n",
    "max_target_len = max(len(seq) for seq in decoder_target_sequences)\n",
    "max_len = max(max_input_len, max_target_len)\n",
    "\n",
    "### ğŸ§± 8. Padding uygula\n",
    "encoder_input = pad_sequences(input_sequences, maxlen=max_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input_sequences, maxlen=max_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target_sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "### ğŸ“Œ 10. Vocab boyutlarÄ±\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "target_vocab_size = len(target_tokenizer.word_index) + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c6bfd5",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6271118c",
   "metadata": {},
   "source": [
    "## ğŸ“¦ 6ï¸âƒ£ Veriyi ayÄ±r â†’ X, y_input, y_target\n",
    "\n",
    "* Bu adÄ±mda modelin 3 temel girdisini oluÅŸturacaÄŸÄ±z:\n",
    "\n",
    "\n",
    "X =>\tEncoder'a gidecek input (kullanÄ±cÄ±nÄ±n mesajÄ±)\n",
    "\n",
    "y_input =>\tDecoder'a giriÅŸ olarak verilen diziler (<start token'lÄ±)\n",
    "\n",
    "y_target =>\t Modelin Ã¼retmesi gereken doÄŸru Ã§Ä±ktÄ± (<end token'lÄ±)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d90580",
   "metadata": {},
   "source": [
    "#### ğŸ§  KÄ±saca:\n",
    "y_input = Decoderâ€™a â€œtahmin etmeye baÅŸlaâ€ demek\n",
    "\n",
    "y_target = â€œNe tahmin etmen gerekiyorduâ€ demek\n",
    "\n",
    "Bu ikisinin ayrÄ±lmasÄ± = Teacher Forcing dediÄŸimiz tekniÄŸin temelidir\n",
    "\n",
    "#### ğŸ› ï¸ EÄŸer bu ayrÄ±mÄ± yapmazsan...\n",
    "Model decoderâ€™a giriÅŸ alamaz, Ã§Ä±ktÄ± Ã¼retemez\n",
    "\n",
    "loss hesaplamasÄ± yanlÄ±ÅŸ olur (Ã§Ä±ktÄ±yÄ± neyle kÄ±yaslayacaÄŸÄ±nÄ± bilemez)\n",
    "\n",
    "EÄŸitim baÅŸarÄ±sÄ±z olur ya da saÃ§ma sonuÃ§lar Ã¼retir\n",
    "\n",
    "#### ğŸ“ SonuÃ§:\n",
    "Encoderâ€“Decoder mimarilerde doÄŸru input ve target ayrÄ±mÄ±, modelin dili Ã¶ÄŸrenmesinin temel taÅŸÄ±dÄ±r.\n",
    "\n",
    "Bu nedenle bu adÄ±m, \"Transformerâ€™Ä±n konuÅŸmayÄ± Ã¶ÄŸrenmesini saÄŸlayan yapÄ± taÅŸlarÄ±nÄ±n montajÄ±\" gibidir diyebiliriz ğŸ§©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba91da4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder input â†’ kullanÄ±cÄ± cÃ¼mlesi\n",
    "X = encoder_input\n",
    "\n",
    "# Decoder input â†’ <start> ile baÅŸlayan hedef cÃ¼mle\n",
    "y_input = decoder_input\n",
    "\n",
    "# Decoder target â†’ <end> ile biten gerÃ§ek cevap\n",
    "y_target = decoder_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7c328cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder input Ã¶rneÄŸi: [24  0  0  0  0  0  0  0  0  0  0  0]\n",
      "Decoder input Ã¶rneÄŸi: [ 2 54 14 55  7 56  0  0  0  0  0  0]\n",
      "Decoder target Ã¶rneÄŸi: [54 14 55  7 56  3  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Encoder input Ã¶rneÄŸi:\", X[0])\n",
    "print(\"Decoder input Ã¶rneÄŸi:\", y_input[0])\n",
    "print(\"Decoder target Ã¶rneÄŸi:\", y_target[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c09bc0d",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9f9e7b",
   "metadata": {},
   "source": [
    "## ğŸ§± 7ï¸âƒ£ Transformer Encoderâ€“Decoder Modeli (TensorFlow/Keras)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0c3bc0",
   "metadata": {},
   "source": [
    "* Model iÃ§inde Ã§ok daha farklÄ± terimler gÃ¶receÄŸiz.HatÄ±rlatmak iÃ§in tekrar yazÄ±yorum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4290b792",
   "metadata": {},
   "source": [
    "### ğŸ“ Positional Encoding Nedir?\n",
    "* Transformer modelleri, RNN'lerin aksine veriyi sÄ±rayla iÅŸlemez â€” yani kelimelerin hangi sÄ±rada geldiÄŸini doÄŸrudan bilmez.\n",
    "\n",
    "Ã‡Ã¼nkÃ¼ Attention mekanizmasÄ± aynÄ± anda tÃ¼m kelimelere bakar.\n",
    "\n",
    "Bu da sÄ±rayÄ± \"unutmasÄ±na\" sebep olur.\n",
    "\n",
    "* Ä°ÅŸte bu yÃ¼zden Positional Encoding devreye girer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44360004",
   "metadata": {},
   "source": [
    "####  ğŸ§  TanÄ±m:\n",
    "* Positional Encoding, her kelimenin sÄ±rasÄ±nÄ± modele bildirmek iÃ§in embeddingâ€™lere eklenen Ã¶zel bir sinyaldir.\n",
    "\n",
    "#### ğŸ”¢ NasÄ±l Ã§alÄ±ÅŸÄ±r?\n",
    "* Her pozisyon (0, 1, 2, ...) iÃ§in bir vektÃ¶r Ã¼retilir.\n",
    "\n",
    "* Bu vektÃ¶rler sinÃ¼s ve kosinÃ¼s fonksiyonlarÄ±yla oluÅŸturulur.\n",
    "\n",
    "* BÃ¶ylece model ÅŸu farkÄ± anlayabilir:\n",
    "\n",
    "* â€œ2. kelime ile 5. kelime arasÄ±nda ne kadar mesafe var?â€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587dbbc4",
   "metadata": {},
   "source": [
    "#### ğŸ“Œ SonuÃ§:\n",
    "* Positional Encoding, kelimelerin sÄ±rasÄ±nÄ± modele gizlice Ã¶ÄŸretir\n",
    "\n",
    "* Embeddingâ€™lere eklenir (toplama yapÄ±lÄ±r)\n",
    "\n",
    "* Model artÄ±k sadece ne dediÄŸini deÄŸil, ne zaman dediÄŸini de bilir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f92756d",
   "metadata": {},
   "source": [
    "#### AslÄ±nda bu konu benim de merakÄ±mdÄ±.Yani neden sin/cos kullanÄ±yoruz?Bu hangi amaca hitap ediyor ki?Gelin beraber inceleyelim."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764e7b82",
   "metadata": {},
   "source": [
    "### ğŸ§© Neden sin/kos?\n",
    "* SinÃ¼s ve kosinÃ¼s, ardÄ±ÅŸÄ±k pozisyonlar arasÄ±ndaki farkÄ± dÃ¼zgÃ¼n ve Ã¶ÄŸrenilebilir biÃ§imde taÅŸÄ±r\n",
    "\n",
    "Daha da Ã¶nemlisi:\n",
    "\n",
    "* Model, mutlak pozisyon deÄŸil, pozisyonlar arasÄ± fark Ã¼zerinde Ã¶ÄŸrenir\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c337e0",
   "metadata": {},
   "source": [
    "### Gelin Positional  Encoder'Ä±n kod bloklarÄ±na bakalÄ±mm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2352700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def positionel_encoding(max_len,d_model):\n",
    "\n",
    "# â¤ max_len kadar sÄ±radaki pozisyon numaralarÄ±nÄ± tek tek bir sÃ¼tun vektÃ¶rÃ¼ haline getirdik.\n",
    "    pos = tf.range(max_len,dtype = tf.float32)[:, tf.newaxis]\n",
    "\n",
    "# â¤ d_model, her kelimenin embedding (veya temsil) vektÃ¶rÃ¼nÃ¼n boyutudur. AÅŸaÄŸÄ±daki satÄ±r ise bu boyutlar boyunca pozisyonel sinyallerin nasÄ±l yayÄ±lacaÄŸÄ±nÄ± belirlemek iÃ§in kullanÄ±lÄ±r.\"\n",
    "    i = tf.range(d_model , dtype=tf.float32)[tf.newaxis,:]\n",
    "\n",
    "# â¤ pozisyona gÃ¶re hangi frekansta sinyal (aÃ§Ä±) verileceÄŸini belirler.\n",
    "    angle_rates =  1 / tf.pow(100000.0 ,(2 * ( i//2)) / tf.cast(d_model,tf.float32))\n",
    "\n",
    "# â¤ Her pozisyondaki kelime iÃ§in, her embedding boyutuna karÅŸÄ±lÄ±k gelen aÃ§Ä±sal (frekanslÄ±) sinyali hesapla\n",
    "    angel_rads = pos * angle_rates\n",
    "\n",
    "    sines = tf.math.sin(angel_rads[:, 0::2])\n",
    "    cosines = tf.math.cos(angel_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = tf.concat([sines,cosines] , axis = 1)\n",
    "\n",
    "    return pos_encoding[tf.newaxis , ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040aaeb8",
   "metadata": {},
   "source": [
    "## ğŸ”¢ 1. pos = tf.range(max_len)[:, tf.newaxis]\n",
    "\n",
    "* Ã‡Ä±ktÄ± olarak\n",
    "\n",
    "[[0]\n",
    " [1]\n",
    " [2]\n",
    " [3]\n",
    " [4]]\n",
    "\n",
    " ##### ğŸ“Œ AnlamÄ±:\n",
    "\n",
    "* Bu, her pozisyonu temsil eder.\n",
    "* Yani \"Merhaba dÃ¼nya bugÃ¼n nasÄ±lsÄ±n?\" cÃ¼mlesi varsa:\n",
    "\n",
    "\"Merhaba\" â†’ pozisyon 0\n",
    "\n",
    "\"dÃ¼nya\" â†’ pozisyon 1\n",
    "\n",
    "...\n",
    "\n",
    "* Yani pos = kaÃ§Ä±ncÄ± kelime olduÄŸunu belirler.\n",
    "\n",
    "â¤ max_len kadar sÄ±radaki pozisyon numaralarÄ±nÄ± tek tek bir sÃ¼tun vektÃ¶rÃ¼ haline getirdik."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a4f196",
   "metadata": {},
   "source": [
    "### ğŸ¯ KÄ±saca:\n",
    "* tÄ±pkÄ± tokenizer'da her kelimeye ID verir gibi burada da her pozisyona ID veriyoruz\n",
    "\n",
    "* Ama ID'ler sayÄ±sal deÄŸil, birazdan sinyale dÃ¶nÃ¼ÅŸecek ğŸ§ ğŸ“¡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96e6b88",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£  i = tf.range(d_model)[tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b549af",
   "metadata": {},
   "source": [
    "#### * âœ… Ne yapar?\n",
    "\n",
    "Her embedding boyutunun indeksini Ã§Ä±karÄ±r. Yani \"0. boyut, 1. boyut, 2. boyut, ...\" gibi deÄŸerleri verir.\n",
    "\n",
    "\n",
    "##### *  Ã–rnek: d_model = 4\n",
    "[[0, 1, 2, 3]]\n",
    "\n",
    "0 â†’ embedding'in 1. boyutu\n",
    "\n",
    "1 â†’ embedding'in 2. boyutu\n",
    "\n",
    "...\n",
    "\n",
    "Bu, her vektÃ¶r boyutu iÃ§in indeksleri temsil eder\n",
    "\n",
    "Ve angle_rates hesaplanÄ±rken her boyuta farklÄ± sinyal verebilmek iÃ§in lazÄ±m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a68c868",
   "metadata": {},
   "source": [
    "##### ğŸ§  AmacÄ± ne?\n",
    "Her embedding boyutuna ayrÄ± bir sinyal frekansÄ± verebilmek.\n",
    "Bu, positional encoding'in sinÃ¼s/kosinÃ¼s hesaplarÄ±nda kullanÄ±lÄ±r."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5b08a6",
   "metadata": {},
   "source": [
    "##### ğŸ“Œ Åunu unutma:\n",
    "* pos â†’ pozisyonlar (0. kelime, 1. kelime...)\n",
    "\n",
    "* i â†’ embedding boyutu indeksleri (0. boyut, 1. boyut...)\n",
    "\n",
    "* pos satÄ±rdÄ±r â†’ her kelime sÄ±rasÄ± iÃ§in bir vektÃ¶r\n",
    "\n",
    "* i sÃ¼tundur â†’ her vektÃ¶rÃ¼n kaÃ§Ä±ncÄ± boyutu olduÄŸunu belirtir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d10bcb0",
   "metadata": {},
   "source": [
    "#### ğŸ“Œ KÄ±sa ve Net TanÄ±m:\n",
    "* i = tf.range(d_model)[tf.newaxis, :]\n",
    "\n",
    "â¤ Her pozisyon vektÃ¶rÃ¼nÃ¼n hangi boyutuna hangi frekansla sinyal verileceÄŸini belirlemek iÃ§in kullanÄ±lÄ±r."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876f6973",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ ğŸ“ angle_rates = 1 / tf.pow(10000., (2 * (i // 2)) / d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b53e5fb",
   "metadata": {},
   "source": [
    "* Bu satÄ±r = pozisyona gÃ¶re hangi frekansta sinyal (aÃ§Ä±) verileceÄŸini belirler.\n",
    "\n",
    "* Yani: â€œBu embedding boyutunda nasÄ±l bir sinyal eÄŸrisi kullanayÄ±m?â€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c57b892",
   "metadata": {},
   "source": [
    "#### ğŸ§  Ne Anlama Geliyor?\n",
    "ğŸ¯ AmaÃ§:\n",
    "\n",
    "* Her embedding boyutuna farklÄ± frekanslÄ± sinyal vermek\n",
    "\n",
    "* BÃ¶ylece pozisyon farklarÄ± hem kÃ¼Ã§Ã¼k hem bÃ¼yÃ¼k Ã¶lÃ§eklerde yakalanabilir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d65158f",
   "metadata": {},
   "source": [
    "### ğŸ” ParÃ§a ParÃ§a Ä°nceleyelim:\n",
    "âœ… i // 2\n",
    "\n",
    "* sin/cos dÃ¶nÃ¼ÅŸÃ¼mÃ¼ iÃ§in Ã§ift-tek ayrÄ±mÄ±\n",
    "\n",
    "* BoyutlarÄ± 2â€™ÅŸer 2â€™ÅŸer gruplandÄ±rmak iÃ§in\n",
    "\n",
    "âœ… (2 * (i // 2)) / d_model\n",
    "\n",
    "* d_modelâ€™e oranla ne kadar hÄ±zlÄ± deÄŸiÅŸim olacak?\n",
    "\n",
    "* Daha kÃ¼Ã§Ã¼k boyutlarda yÃ¼ksek frekans (detaylÄ± sinyal)\n",
    "\n",
    "* Daha bÃ¼yÃ¼k boyutlarda dÃ¼ÅŸÃ¼k frekans (genel yapÄ±)\n",
    "\n",
    "âœ… tf.pow(10000., ...)\n",
    "\n",
    "* Bu, frekansÄ± Ã¼stel olarak azaltmak iÃ§in kullanÄ±lÄ±r\n",
    "\n",
    "* 10000 sabiti â†’ paperâ€™da Ã¶nerilen sabit; sinyalleri yeterince seyreltiyor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47919d2f",
   "metadata": {},
   "source": [
    "####  ğŸ’¡ Neden Bu Kadar Ã–zenli?\n",
    "* Ã‡Ã¼nkÃ¼ bazÄ± kelime iliÅŸkileri kÄ±sa mesafededir (Ã¶rneÄŸin: \"merhaba â†’ nasÄ±lsÄ±n\"),\n",
    "bazÄ±larÄ± uzundur (\"bugÃ¼n â†’ dÄ±ÅŸarÄ±sÄ± â†’ hava â†’ gÃ¼zel\")\n",
    "\n",
    "* Modelin her mesafeye gÃ¶re sinyali olsun diye Ã§ok frekanslÄ± bir yapÄ± gerekir â†’ iÅŸte bu satÄ±r bunun iÃ§indir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eacb7a",
   "metadata": {},
   "source": [
    "Terim ====== \tNe iÅŸe yarar?\n",
    "\n",
    "10000 =>\tÃœssÃ¼n bazÄ±, frekanslarÄ± yaymak iÃ§in\n",
    "\n",
    "2i/d_model =>\tEmbedding boyutuna gÃ¶re frekansÄ± Ã¶lÃ§eklemek\n",
    "\n",
    "i // 2 =\tAynÄ± frekansÄ± sin/cos olarak Ã§ift-tek boyutlara daÄŸÄ±tmak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d63f82f",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ ğŸ“¡ angle_rads = pos * angle_rates\n",
    "\n",
    "* Her pozisyondaki kelime iÃ§in, her embedding boyutuna karÅŸÄ±lÄ±k gelen aÃ§Ä±sal (frekanslÄ±) sinyali hesaplar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e25856c",
   "metadata": {},
   "source": [
    "##### ğŸ“ Ne Oluyor Burada?\n",
    "* pos â†’ her kelimenin sÄ±rasÄ± (0, 1, 2, 3, ...) â†’ shape: [max_len, 1]\n",
    "\n",
    "* angle_rates â†’ her embedding boyutu iÃ§in frekans katsayÄ±sÄ± â†’ shape: [1, d_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d1b066",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ ğŸ›ï¸ Sin / Cos Uygulama ve Positional Encoding OluÅŸturma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea38a117",
   "metadata": {},
   "source": [
    "#### ğŸ” SatÄ±r SatÄ±r AÃ§Ä±klama:\n",
    "ğŸ§ª 1. sines = sin(angle_rads[:, 0::2])\n",
    "\n",
    "* Her kelime iÃ§in Ã§ift numaralÄ± boyutlara sinÃ¼s uygula\n",
    "\n",
    "* Yani: 0, 2, 4, 6, 8, ...\n",
    "\n",
    "ğŸ§Š 2. cosines = cos(angle_rads[:, 1::2])\n",
    "\n",
    "* Her kelime iÃ§in tek numaralÄ± boyutlara kosinÃ¼s uygula\n",
    "\n",
    "* Yani: 1, 3, 5, 7, 9, ...\n",
    "\n",
    "ğŸ¯ Sin/cos karÄ±ÅŸÄ±mÄ± â†’ faz farkÄ± ekleyerek zenginleÅŸtirilmiÅŸ sinyal yapÄ±sÄ± oluÅŸturur\n",
    "(sin ve cos aynÄ± frekansta ama 90 derece kayÄ±k = sinyal farklarÄ±nÄ± bÃ¼yÃ¼tÃ¼yor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d66285",
   "metadata": {},
   "source": [
    "#### ğŸ”— 3. tf.concat([sines, cosines], axis=-1)\n",
    "* sines ve cosines dizilerini yan yana birleÅŸtir\n",
    "\n",
    "* SonuÃ§ = [max_len, d_model] boyutunda positional sinyal tablosu\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287fa28a",
   "metadata": {},
   "source": [
    "#### ğŸ§± 4. return pos_encoding[tf.newaxis, ...]\n",
    "* Bu satÄ±rla shape ÅŸu hale gelir: [1, max_len, d_model]\n",
    "\n",
    "* Yani bu encoding, batchâ€™e uygun hale gelir ve direkt embedding ile toplanabilir:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50074bd",
   "metadata": {},
   "source": [
    "## ğŸ§© Positional Encoding â€“ AdÄ±m AdÄ±m Ã–zet\n",
    "\n",
    "| AdÄ±m                  | Ne yaptÄ±?                                                                 |\n",
    "|-----------------------|---------------------------------------------------------------------------|\n",
    "| `pos`                | Her kelimenin cÃ¼mledeki sÄ±rasÄ±nÄ± aldÄ±                                     |\n",
    "| `i`                  | Embedding boyutlarÄ±nÄ±n indekslerini oluÅŸturdu                             |\n",
    "| `angle_rates`        | Her embedding boyutu iÃ§in frekans hesaplama katsayÄ±sÄ± belirledi            |\n",
    "| `pos * angle_rates`  | Her pozisyon-boyut kombinasyonu iÃ§in aÃ§Ä±sal deÄŸerler hesapladÄ±             |\n",
    "| `sin / cos`          | Sinyalleri faz farkÄ±yla dÃ¶nÃ¼ÅŸtÃ¼rerek pozisyonel bilgi kazandÄ±rdÄ±           |\n",
    "| `concat`             | Sin ve cos verilerini birleÅŸtirerek final sinyal vektÃ¶rÃ¼nÃ¼ oluÅŸturdu       |\n",
    "| `+ embedding`        | Embedding vektÃ¶rÃ¼ne pozisyon bilgisini ekledi â†’ model sÄ±ralarÄ± â€œgÃ¶rÃ¼râ€ âœ…   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7489ee",
   "metadata": {},
   "source": [
    "## ğŸ“ Positional Encoding Son Demler\n",
    "\n",
    "- Positional Encoding, aslÄ±nda **embedding katmanÄ±na eklenen sinyaldir**.\n",
    "- Model sÄ±rayÄ± bilemediÄŸi iÃ§in, bu sinyalle **kelimenin kaÃ§Ä±ncÄ± sÄ±rada olduÄŸunu** anlar.\n",
    "- Ä°lk olarak, cÃ¼mledeki **her pozisyonu (`pos`)** temsil eden bir vektÃ¶r oluÅŸturduk.\n",
    "- ArdÄ±ndan, her **embedding boyutu (`d_model`)** iÃ§in bir boyut vektÃ¶rÃ¼ (`i`) oluÅŸturduk.\n",
    "- Sonra bu boyutlara gÃ¶re **aÃ§Ä±sal frekans katsayÄ±larÄ± (`angle_rates`)** belirledik.\n",
    "- Bu frekanslar ile pozisyonlarÄ± Ã§arparak **aÃ§Ä±sal deÄŸerler (`angle_rads`)** elde ettik.\n",
    "- Daha sonra Ã§ift indeksli boyutlara `sin`, tek indeksli boyutlara `cos` uyguladÄ±k.\n",
    "- Bu `sin` ve `cos` sinyallerini birleÅŸtirerek **pozisyonel sinyal vektÃ¶rÃ¼** oluÅŸturduk.\n",
    "- En sonunda bu vektÃ¶rÃ¼ embedding Ã§Ä±ktÄ±sÄ±yla toplayarak **modelin sÄ±ralamayÄ± \"gÃ¶rmesini\" saÄŸladÄ±k**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5828e26d",
   "metadata": {},
   "source": [
    "-----------\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7f324e",
   "metadata": {},
   "source": [
    "# Åimdi Positionel Encodingden Sonra Gelen Embedding KatmanÄ±nÄ± Ä°nceleyelim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c5000c",
   "metadata": {},
   "source": [
    "-----\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aece8b00",
   "metadata": {},
   "source": [
    "#   âœ… Embedding + Positional Encoding KatmanÄ± (Fonksiyon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91ab427",
   "metadata": {},
   "source": [
    "* AslÄ±nda embedding katmanÄ±nÄ± biliyoruz.Metinsel deÄŸerlerde kullandÄ±ÄŸÄ±mÄ±z bir vektÃ¶r dÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼.Bundna Ã¶nce de size zaten positionel encoding i anlatmÄ±ÅŸtÄ±m.Åimdi bu positionel encoding katmaÄ±nÄ± embedding e baÄŸlamamÄ±z gerekecek.Gelin bu iÅŸlemlere bakalÄ±m.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f923be5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Add, Lambda\n",
    "\n",
    "def token_and_position_embedding(vocab_size, max_len, d_model):\n",
    "    inputs = Input(shape=(None,), name=\"input_tokens\")\n",
    "\n",
    "    x = Embedding(input_dim=vocab_size, output_dim=d_model)(inputs)\n",
    "\n",
    "    # positional encoding Ã¶nceden sabit oluÅŸturulmuÅŸ (max_len kadar)\n",
    "    pos_encoding = positionel_encoding(max_len, d_model)\n",
    "\n",
    "    # Lambda ile slice iÅŸlemini runtimeâ€™da yapÄ±yoruz\n",
    "    def slice_position(x_input):\n",
    "        seq_len = tf.shape(x_input)[1]\n",
    "        return pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    pos_slice = Lambda(slice_position)(x)\n",
    "\n",
    "    x = Add()([x, pos_slice])\n",
    "\n",
    "    return Model(inputs=inputs, outputs=x, name=\"TokenPosEmbedding\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9d7767",
   "metadata": {},
   "source": [
    "### ğŸ“Œ KullanÄ±mÄ±:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "800d12db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hdgn5\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:216: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# encoder_inputs bizim encoder iÃ§in Input katmanÄ±mÄ±z\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "encoder_inputs = layers.Input(shape=(None,), name=\"encoder_input\")\n",
    "embedding_layer = token_and_position_embedding(\n",
    "    vocab_size=input_vocab_size, max_len=max_len, d_model=128\n",
    ")\n",
    "\n",
    "# Ã§aÄŸÄ±rdÄ±ÄŸÄ±mÄ±zda sanki bir layer gibi davranÄ±r\n",
    "x = embedding_layer(encoder_inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a3dbbf",
   "metadata": {},
   "source": [
    "--------\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2fcc6c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Åimdi SÄ±rada Encoder YapÄ±sÄ± Var.Merak Etmeyin Bu FonksiyonlarÄ± Daha GÃ¼Ã§lÃ¼ Hale GetireceÄŸiz.Bu YalnÄ±zca Bir BaÅŸlangÄ±Ã§Ã§..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceb6dc8",
   "metadata": {},
   "source": [
    "-----\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33fa54c",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ build_encoder() Fonksiyonu â€” Tek Blok Encoder YapÄ±sÄ±\n",
    "\n",
    "####  ğŸ§± build_encoder() Fonksiyonunun AmacÄ±\n",
    "\n",
    "- Bu fonksiyon, Transformer mimarisindeki **Encoder bloÄŸunu** oluÅŸturur.\n",
    "- Encoder, verilen token dizisinden (yani giriÅŸ cÃ¼mlesinden), **sÄ±ralÄ± ve baÄŸlama duyarlÄ± bir vektÃ¶r temsili** Ã¼retir.\n",
    "- Ä°Ã§erisinde:\n",
    "  - Embedding + Positional Encoding (kelimenin anlamÄ± + sÄ±rasÄ±)\n",
    "  - Multi-Head Self Attention (kelimeler arasÄ± iliÅŸki Ã¶ÄŸrenimi)\n",
    "  - Feed Forward Network (her pozisyonu bireysel iÅŸler)\n",
    "  - Residual baÄŸlantÄ±lar + Layer Normalization (Ã¶ÄŸrenmeyi stabilize eder)\n",
    "- Modelin giriÅŸ kÄ±smÄ±nda (input side) yer alÄ±r ve decoderâ€™a bilgi saÄŸlar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c248693c",
   "metadata": {},
   "source": [
    "## ğŸ”§ Feed Forward Network (FFN) Nedir?\n",
    "\n",
    "- Transformerâ€™daki her encoder/decoder bloÄŸunda bulunan kÃ¼Ã§Ã¼k sinir aÄŸÄ±dÄ±r.\n",
    "- Her kelime pozisyonuna **ayrÄ± ayrÄ±** uygulanÄ±r.\n",
    "- YapÄ±sÄ± genellikle:\n",
    "\n",
    "  Dense(d_model * 4, activation='relu') â†’ Dense(d_model)\n",
    "  \n",
    "- Attention Ã§Ä±ktÄ±sÄ±nÄ± iÅŸler, modeli derinleÅŸtirir ve anlam Ã§Ä±karÄ±m gÃ¼cÃ¼nÃ¼ artÄ±rÄ±r.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97007334",
   "metadata": {},
   "source": [
    "#### ğŸ¯ FFN nedir, ne iÅŸe yarar?\n",
    "* Transformer iÃ§inde her bir pozisyon (token) iÃ§in ayrÄ± ayrÄ± uygulanan kÃ¼Ã§Ã¼k bir sinir aÄŸÄ±dÄ±r.\n",
    "\n",
    "* Yani: Kelime baÅŸÄ±na â€œbireysel olarak dÃ¼ÅŸÃ¼nmeâ€ mekanizmasÄ±dÄ±r ğŸ¤–ğŸ§ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aafe3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dense(d_model * 4, activation='relu')(x)\n",
    "x = Dense(d_model)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eafe069",
   "metadata": {},
   "source": [
    "Bu ÅŸu anlama gelir:\n",
    "\n",
    "* Ä°lk katman: GeniÅŸlet â†’ d_model â†’ 4 Ã— d_model\n",
    "\n",
    "* ReLU aktivasyonu: doÄŸrusal olmayanlÄ±k katar\n",
    "\n",
    "* Ä°kinci katman: Daralt â†’ 4 Ã— d_model â†’ d_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f58bc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "def build_encoder(vocab_size, max_len, d_model, num_heads):\n",
    "    # 1ï¸âƒ£ GiriÅŸ katmanÄ±\n",
    "    encoder_inputs = layers.Input(shape=(None,), name=\"encoder_input\")\n",
    "\n",
    "    # 2ï¸âƒ£ Embedding + Positional Encoding (hazÄ±r fonksiyon)\n",
    "    embedding_layer = token_and_position_embedding(vocab_size, max_len, d_model)\n",
    "    x = embedding_layer(encoder_inputs)\n",
    "\n",
    "    # 3ï¸âƒ£ Multi-Head Self-Attention\n",
    "    attn_out = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(x, x)\n",
    "\n",
    "    # 4ï¸âƒ£ Residual + Layer Normalization\n",
    "    x = layers.Add()([x, attn_out])\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "    # 5ï¸âƒ£ Feed Forward Network\n",
    "    ffn = layers.Dense(d_model * 4, activation='relu')(x)\n",
    "    ffn = layers.Dense(d_model)(ffn)\n",
    "\n",
    "    # 6ï¸âƒ£ Residual + Layer Normalization\n",
    "    x = layers.Add()([x, ffn])\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "    # 7ï¸âƒ£ Modeli dÃ¶ndÃ¼r\n",
    "    return Model(inputs=encoder_inputs, outputs=x, name=\"TransformerEncoder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfaf8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"TransformerEncoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"TransformerEncoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ encoder_input       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ TokenPosEmbedding   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">55,296</span> â”‚ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,200,960</span> â”‚ TokenPosEmbeddinâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentioâ€¦</span> â”‚                   â”‚            â”‚ TokenPosEmbeddinâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ TokenPosEmbeddinâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalization â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)  â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> â”‚ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ encoder_input       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ TokenPosEmbedding   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m)   â”‚     \u001b[38;5;34m55,296\u001b[0m â”‚ encoder_input[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m)   â”‚  \u001b[38;5;34m4,200,960\u001b[0m â”‚ TokenPosEmbeddinâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mMultiHeadAttentioâ€¦\u001b[0m â”‚                   â”‚            â”‚ TokenPosEmbeddinâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_2 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ TokenPosEmbeddinâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalization â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m)   â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m2048\u001b[0m)  â”‚  \u001b[38;5;34m1,050,624\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m)   â”‚  \u001b[38;5;34m1,049,088\u001b[0m â”‚ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_3 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m)   â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,358,016</span> (24.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,358,016\u001b[0m (24.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,358,016</span> (24.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,358,016\u001b[0m (24.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ğŸ“Œ KullanÄ±mÄ±:\n",
    "\n",
    "encoder = build_encoder(\n",
    "    vocab_size=input_vocab_size,\n",
    "    max_len=max_len,\n",
    "    d_model=512,\n",
    "    num_heads=4\n",
    ")\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830ff495",
   "metadata": {},
   "source": [
    "### ğŸ¯ Self-Attention Neydi?\n",
    "* Bir kelimenin diÄŸer kelimelere olan baÄŸlamÄ±nÄ± Ã¶ÄŸrenmesi.\n",
    "\n",
    "Ã–rnek:\n",
    "\n",
    "* â€œKedi koltuÄŸun Ã¼stÃ¼nde uyuyor.â€\n",
    "\n",
    "* â€œkediâ€ â†’ dikkatini â€œuyuyorâ€ kelimesine vermeli\n",
    "\n",
    "* â€œkoltuÄŸunâ€ â†’ konum bilgisiyle iliÅŸkili\n",
    "\n",
    "ğŸ§  Self-attention bunu yapar:\n",
    "\n",
    "* Her kelime, diÄŸer kelimelerle olan iliÅŸkisini kendisi Ã§Ã¶zer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021b7a1c",
   "metadata": {},
   "source": [
    "## ğŸ¤” Peki neden Multi-Head Attention?\n",
    "\n",
    "### ğŸ” 1. FarklÄ± BakÄ±ÅŸ AÃ§Ä±larÄ± SaÄŸlar\n",
    "\n",
    "Her â€œheadâ€ = farklÄ± bir Ã¶ÄŸrenme perspektifi saÄŸlar.\n",
    "\n",
    "#### ğŸ§  Ã–rnek:\n",
    "\n",
    "| Head 1              | Head 2               | Head 3                    |\n",
    "|---------------------|----------------------|---------------------------|\n",
    "| dilbilgisel iliÅŸki  | duygusal tonlama     | zamansal baÄŸlam          |\n",
    "| \"Ã¶zne-fiil\" iliÅŸkisi | \"sevgi/korku\" analizi | \"Ã¶nceki/sonraki kelime\" iliÅŸkisi |\n",
    "\n",
    "Tek bir self-attention bu baÄŸlamlarÄ± aynÄ± anda yakalayamaz.  \n",
    "Ama birden fazla attention head, **paralel zihinler gibi** Ã§alÄ±ÅŸarak her biri farklÄ± bir bilgi yÃ¶nÃ¼ne odaklanabilir. ğŸ§ ğŸ§ ğŸ§ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240008b3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### ğŸ” 2. FarklÄ± Projeksiyon UzaylarÄ±nda Hesaplama\n",
    "\n",
    "Her head:\n",
    "- Kendi `Wq`, `Wk`, `Wv` aÄŸÄ±rlÄ±klarÄ±nÄ± kullanÄ±r\n",
    "- Yani aynÄ± input Ã¼zerinden farklÄ± projeksiyonlar oluÅŸturur\n",
    "- Bu, daha **geniÅŸ iliÅŸki Ã§eÅŸitliliÄŸi** Ã¶ÄŸrenmesini saÄŸlar\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ” 3. ZenginleÅŸtirilmiÅŸ Temsil\n",
    "\n",
    "TÃ¼m head'lerin Ã§Ä±ktÄ±sÄ± birleÅŸtirilir (`concat`) ve ardÄ±ndan bir `Dense` katmanla orijinal boyuta dÃ¶nÃ¼lÃ¼r:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa50d7e3",
   "metadata": {},
   "source": [
    "\n",
    "Bu sayede farklÄ± baÄŸlamlar iÃ§eren Ã§Ä±ktÄ±lar, tek bir gÃ¼Ã§lÃ¼ vektÃ¶rde toplanÄ±r.\n",
    "\n",
    "\n",
    "### âœ… Ã–zet\n",
    "\n",
    "| Ã–zellik                  | Tek Head             | Multi-Head                         |\n",
    "|--------------------------|----------------------|------------------------------------|\n",
    "| Perspektif               | Tek bakÄ±ÅŸ aÃ§Ä±sÄ±      | FarklÄ± bakÄ±ÅŸ aÃ§Ä±larÄ±nÄ±n birleÅŸimi  |\n",
    "| Hesaplama                | Sabit projeksiyon    | FarklÄ± aÄŸÄ±rlÄ±klarla farklÄ± dikkat  |\n",
    "| Ã–ÄŸrenme kapasitesi       | SÄ±nÄ±rlÄ±              | Daha esnek ve gÃ¼Ã§lÃ¼                |\n",
    "| BaÄŸlam Ã§eÅŸitliliÄŸi       | DÃ¼ÅŸÃ¼k                | YÃ¼ksek                             |\n",
    "\n",
    "Multi-head attention sayesinde model, dilin Ã§ok katmanlÄ± doÄŸasÄ±nÄ± daha iyi kavrayabilir. ğŸ”¥\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a772ce1d",
   "metadata": {},
   "source": [
    "## ğŸ§± Profesyonel build_encoder() â€” Temiz ve KatmanlaÅŸtÄ±rÄ±lmÄ±ÅŸ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e9d935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Embedding, Dropout, LayerNormalization, MultiHeadAttention\n",
    "\n",
    "\n",
    "def add_and_norm(x,sublayer_output,dp=0.3):\n",
    "    dropped = layers.Dropout(dp)(sublayer_output)\n",
    "    added = layers.Add()([x,dropped])\n",
    "\n",
    "    return layers.LayerNormalization(epsilon=1e-6)(added)\n",
    "\n",
    "def feed_forward_network(d_model):\n",
    "    return tf.keras.Sequential([\n",
    "        layers.Dense(d_model * 4, activation='relu'),\n",
    "        layers.Dense(d_model),\n",
    "        layers.Dropout(0.3)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17c0e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_block(x, d_model, num_heads, dropout_rate=0.1):\n",
    "    attn_output = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(x, x)\n",
    "    x = add_and_norm(x, attn_output, dp=dropout_rate)\n",
    "\n",
    "    ffn = tf.keras.Sequential([\n",
    "        layers.Dense(d_model * 4, activation='relu'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(d_model)\n",
    "    ])\n",
    "    ffn_output = ffn(x)\n",
    "    x = add_and_norm(x, ffn_output, dp=dropout_rate)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1cbc9bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder(vocab_size, max_len, d_model, num_heads, num_layers=1, dropout_rate=0.1):\n",
    "    encoder_inputs = layers.Input(shape=(None,), name=\"encoder_input\")\n",
    "\n",
    "    embedding_layer = token_and_position_embedding(vocab_size, max_len, d_model)\n",
    "    x = embedding_layer(encoder_inputs)\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        x = encoder_block(x, d_model, num_heads, dropout_rate)\n",
    "\n",
    "    return Model(inputs=encoder_inputs, outputs=x, name=\"TransformerEncoder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b062887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"TransformerEncoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"TransformerEncoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ encoder_input       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ TokenPosEmbedding   â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">27,648</span> â”‚ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,051,904</span> â”‚ TokenPosEmbeddinâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentioâ€¦</span> â”‚                   â”‚            â”‚ TokenPosEmbeddinâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ TokenPosEmbeddinâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalization â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sequential          â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,568</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sequential[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,051,904</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentioâ€¦</span> â”‚                   â”‚            â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sequential_1        â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,568</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sequential_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,051,904</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentioâ€¦</span> â”‚                   â”‚            â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sequential_2        â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,568</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_11          â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sequential_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,051,904</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentioâ€¦</span> â”‚                   â”‚            â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_13          â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ add_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sequential_3        â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,568</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_15          â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sequential_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ add_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ encoder_input       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ TokenPosEmbedding   â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚     \u001b[38;5;34m27,648\u001b[0m â”‚ encoder_input[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚  \u001b[38;5;34m1,051,904\u001b[0m â”‚ TokenPosEmbeddinâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mMultiHeadAttentioâ€¦\u001b[0m â”‚                   â”‚            â”‚ TokenPosEmbeddinâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_2 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ TokenPosEmbeddinâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalization â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sequential          â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚    \u001b[38;5;34m525,568\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mSequential\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sequential[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_3 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚  \u001b[38;5;34m1,051,904\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mMultiHeadAttentioâ€¦\u001b[0m â”‚                   â”‚            â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_4 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sequential_1        â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚    \u001b[38;5;34m525,568\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mSequential\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sequential_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_5 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚  \u001b[38;5;34m1,051,904\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mMultiHeadAttentioâ€¦\u001b[0m â”‚                   â”‚            â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_9 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_6 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sequential_2        â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚    \u001b[38;5;34m525,568\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mSequential\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_11          â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sequential_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_7 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚  \u001b[38;5;34m1,051,904\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mMultiHeadAttentioâ€¦\u001b[0m â”‚                   â”‚            â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_13          â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_8 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ add_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sequential_3        â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚    \u001b[38;5;34m525,568\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mSequential\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_15          â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sequential_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_9 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ add_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,341,632</span> (24.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,341,632\u001b[0m (24.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,341,632</span> (24.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,341,632\u001b[0m (24.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder = build_encoder(\n",
    "    vocab_size=input_vocab_size,\n",
    "    max_len=max_len,\n",
    "    d_model=256,\n",
    "    num_heads=4,\n",
    "    num_layers=4  # ya da kaÃ§ katman gÃ¶rmek istiyorsan\n",
    ")\n",
    "\n",
    "encoder.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe267f0",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5293e20",
   "metadata": {},
   "source": [
    "## ğŸ” HatÄ±rlatma: Transformer Decoder Ne Yapar?\n",
    "### ğŸ“¤ Encoderâ€™dan gelen bilgileri kullanÄ±r\n",
    "### ğŸ§  Kendi geÃ§miÅŸ Ã§Ä±ktÄ±larÄ±yla yeni kelime tahmini yapar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b3e009",
   "metadata": {},
   "source": [
    "#### ğŸ”§ YapÄ±sÄ±:\n",
    "Her decoder bloÄŸu ÅŸunlarÄ± iÃ§erir:\n",
    "\n",
    "* Masked Multi-Head Self Attention\n",
    "\n",
    "â†’ Kendi Ã¶nceki Ã§Ä±ktÄ±lara bakar (geleceÄŸi gÃ¶rmez âŒ)\n",
    "\n",
    "* Encoderâ€“Decoder Attention\n",
    "\n",
    "â†’ Encoderâ€™Ä±n Ã§Ä±ktÄ±sÄ±na dikkat eder\n",
    "\n",
    "* Feed Forward Network\n",
    "\n",
    "â†’ Kelimeyi anlam olarak iÅŸler\n",
    "\n",
    "* Residual + LayerNorm\n",
    "\n",
    "â†’ Her adÄ±mda stabilite saÄŸlar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a11cca",
   "metadata": {},
   "source": [
    "### ğŸ” 1ï¸âƒ£ Decoderâ€™da Neden Yine Multi-Head Attention?\n",
    "Ã‡Ã¼nkÃ¼ decoder da:\n",
    "\n",
    "* Kelimeler arasÄ±ndaki iliÅŸkileri kurmak istiyor\n",
    "\n",
    "* Ama bunu paralel ve baÄŸlamlÄ± ÅŸekilde yapmak istiyor\n",
    "\n",
    "* AynÄ± encoder gibi, decoder da:\n",
    "\n",
    "* Kendi geÃ§miÅŸ Ã§Ä±ktÄ±larÄ±nÄ±n baÄŸlamÄ±nÄ± anlamaya Ã§alÄ±ÅŸÄ±r\n",
    "\n",
    "* Ve bunu birden fazla â€œbakÄ±ÅŸ aÃ§Ä±sÄ±ylaâ€ yaparsa Ã§ok daha zengin temsil oluÅŸur\n",
    "\n",
    "### ğŸ¯ Multi-head ne saÄŸlar?\n",
    "\n",
    "* Head 1: dilbilgisel yapÄ±\n",
    "\n",
    "* Head 2: geÃ§miÅŸ anahtar kelimeye dikkat\n",
    "\n",
    "* Head 3: zaman/zaman dÄ±ÅŸÄ± baÄŸlantÄ±\n",
    "\n",
    "Hepsi birleÅŸtirilir = Ã§ok katmanlÄ± anlam Ã§Ã¶zÃ¼mÃ¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbeb02e",
   "metadata": {},
   "source": [
    "### ğŸ“š GPT-2, GPT-3, ChatGPT hepsi ne kullanÄ±yor?\n",
    "* Transformer decoder only\n",
    "\n",
    "* Hepsi multi-head self-attention kullanÄ±yor\n",
    "\n",
    "Ã‡Ã¼nkÃ¼ bu:\n",
    "\n",
    "* Paralel\n",
    "\n",
    "* Dikkatli\n",
    "\n",
    "* Ã–lÃ§eklenebilir\n",
    "\n",
    "Her kelimenin diÄŸerleriyle baÄŸÄ±nÄ± Ã§oklu seviyede kurabiliyor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693c8ff1",
   "metadata": {},
   "source": [
    "### âœ… 1ï¸âƒ£ decoder_block() Fonksiyonu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267f70b2",
   "metadata": {},
   "source": [
    "* Bunu Ã¶nceki encoder yapÄ±sÄ±na gÃ¶re tanÄ±mlÄ±yoruz. 2 Attention + 1 FFN + residual + dropout + layernorm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1127b079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(x,enc_output,d_model,num_heads,dp=0.3):\n",
    "\n",
    "    attn1 = layers.MultiHeadAttention(num_heads=num_heads,key_dim=d_model)(x,x)\n",
    "\n",
    "    x = add_and_norm(x,attn1,dp=dp)\n",
    "\n",
    "    attn2 = layers.MultiHeadAttention(num_heads=num_heads,key_dim=d_model)(x,enc_output)\n",
    "    x = add_and_norm(x,attn2,dp = dp)\n",
    "\n",
    "    ffn = tf.keras.Sequential([\n",
    "        layers.Dense(d_model * 4,activation=\"relu\"),\n",
    "        layers.Dropout(dp),\n",
    "        layers.Dense(d_model)\n",
    "        ])\n",
    "    \n",
    "    ffn_out = ffn(x)\n",
    "    x = add_and_norm(x,ffn_out,dp=dp)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b34db3a",
   "metadata": {},
   "source": [
    "### âœ… 2ï¸âƒ£ build_decoder() Fonksiyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8cdc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decoder(vocab_size, max_len, d_model, num_heads, num_layers=4, dropout_rate=0.1):\n",
    "    decoder_inputs = layers.Input(shape=(None,), name=\"decoder_input\")\n",
    "    encoder_outputs = layers.Input(shape=(None, d_model), name=\"encoder_output\")  # DÄ°KKAT!\n",
    "\n",
    "    embedding_layer = token_and_position_embedding(vocab_size, max_len, d_model)\n",
    "    x = embedding_layer(decoder_inputs)\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        x = decoder_block(x, encoder_outputs, d_model, num_heads, dropout_rate)\n",
    "\n",
    "    return Model(inputs=[decoder_inputs, encoder_outputs], outputs=x, name=\"TransformerDecoder\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33643fd3",
   "metadata": {},
   "source": [
    "#### ğŸ“Œ KullanÄ±mÄ±:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90171ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"TransformerDecoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"TransformerDecoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ decoder_input       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ TokenPosEmbedding   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">27,648</span> â”‚ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,577,728</span> â”‚ TokenPosEmbeddinâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentioâ€¦</span> â”‚                   â”‚            â”‚ TokenPosEmbeddinâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_102         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ TokenPosEmbeddinâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_102[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ add_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ encoder_output      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,577,728</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentioâ€¦</span> â”‚                   â”‚            â”‚ encoder_output[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_104         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_104[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ add_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sequential_17       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,568</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_106         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sequential_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_106[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ add_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,577,728</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentioâ€¦</span> â”‚                   â”‚            â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_108         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_108[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ add_65[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,577,728</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentioâ€¦</span> â”‚                   â”‚            â”‚ encoder_output[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_110         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_110[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ add_66[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sequential_18       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,568</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_112         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sequential_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_112[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ add_67[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,577,728</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentioâ€¦</span> â”‚                   â”‚            â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_114         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_114[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ add_68[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,577,728</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentioâ€¦</span> â”‚                   â”‚            â”‚ encoder_output[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_116         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_116[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ add_69[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sequential_19       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,568</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_118         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sequential_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_118[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ add_70[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,577,728</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentioâ€¦</span> â”‚                   â”‚            â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_120         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_120[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ add_71[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,577,728</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentioâ€¦</span> â”‚                   â”‚            â”‚ encoder_output[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_122         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_72 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_122[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ add_72[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sequential_20       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,568</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_124         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sequential_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_73 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_124[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ add_73[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,577,728</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentioâ€¦</span> â”‚                   â”‚            â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_126         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_74 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_126[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ add_74[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,577,728</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentioâ€¦</span> â”‚                   â”‚            â”‚ encoder_output[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_128         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_128[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ add_75[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sequential_21       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,568</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_130         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sequential_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_76 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_130[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ add_76[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ decoder_input       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ TokenPosEmbedding   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚     \u001b[38;5;34m27,648\u001b[0m â”‚ decoder_input[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚  \u001b[38;5;34m1,577,728\u001b[0m â”‚ TokenPosEmbeddinâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mMultiHeadAttentioâ€¦\u001b[0m â”‚                   â”‚            â”‚ TokenPosEmbeddinâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_102         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_62 (\u001b[38;5;33mAdd\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ TokenPosEmbeddinâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_102[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚        \u001b[38;5;34m512\u001b[0m â”‚ add_62[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ encoder_output      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚  \u001b[38;5;34m1,577,728\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mMultiHeadAttentioâ€¦\u001b[0m â”‚                   â”‚            â”‚ encoder_output[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_104         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_63 (\u001b[38;5;33mAdd\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_104[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚        \u001b[38;5;34m512\u001b[0m â”‚ add_63[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sequential_17       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚    \u001b[38;5;34m525,568\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mSequential\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_106         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sequential_17[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_64 (\u001b[38;5;33mAdd\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_106[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚        \u001b[38;5;34m512\u001b[0m â”‚ add_64[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚  \u001b[38;5;34m1,577,728\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mMultiHeadAttentioâ€¦\u001b[0m â”‚                   â”‚            â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_108         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_65 (\u001b[38;5;33mAdd\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_108[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚        \u001b[38;5;34m512\u001b[0m â”‚ add_65[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚  \u001b[38;5;34m1,577,728\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mMultiHeadAttentioâ€¦\u001b[0m â”‚                   â”‚            â”‚ encoder_output[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_110         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_66 (\u001b[38;5;33mAdd\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_110[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚        \u001b[38;5;34m512\u001b[0m â”‚ add_66[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sequential_18       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚    \u001b[38;5;34m525,568\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mSequential\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_112         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sequential_18[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_67 (\u001b[38;5;33mAdd\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_112[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚        \u001b[38;5;34m512\u001b[0m â”‚ add_67[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚  \u001b[38;5;34m1,577,728\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mMultiHeadAttentioâ€¦\u001b[0m â”‚                   â”‚            â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_114         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_68 (\u001b[38;5;33mAdd\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_114[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚        \u001b[38;5;34m512\u001b[0m â”‚ add_68[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚  \u001b[38;5;34m1,577,728\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mMultiHeadAttentioâ€¦\u001b[0m â”‚                   â”‚            â”‚ encoder_output[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_116         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_69 (\u001b[38;5;33mAdd\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_116[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚        \u001b[38;5;34m512\u001b[0m â”‚ add_69[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sequential_19       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚    \u001b[38;5;34m525,568\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mSequential\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_118         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sequential_19[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_70 (\u001b[38;5;33mAdd\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_118[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚        \u001b[38;5;34m512\u001b[0m â”‚ add_70[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚  \u001b[38;5;34m1,577,728\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mMultiHeadAttentioâ€¦\u001b[0m â”‚                   â”‚            â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_120         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_71 (\u001b[38;5;33mAdd\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_120[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚        \u001b[38;5;34m512\u001b[0m â”‚ add_71[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚  \u001b[38;5;34m1,577,728\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mMultiHeadAttentioâ€¦\u001b[0m â”‚                   â”‚            â”‚ encoder_output[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_122         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_72 (\u001b[38;5;33mAdd\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_122[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚        \u001b[38;5;34m512\u001b[0m â”‚ add_72[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sequential_20       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚    \u001b[38;5;34m525,568\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mSequential\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_124         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sequential_20[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_73 (\u001b[38;5;33mAdd\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_124[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚        \u001b[38;5;34m512\u001b[0m â”‚ add_73[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚  \u001b[38;5;34m1,577,728\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mMultiHeadAttentioâ€¦\u001b[0m â”‚                   â”‚            â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_126         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_74 (\u001b[38;5;33mAdd\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_126[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚        \u001b[38;5;34m512\u001b[0m â”‚ add_74[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚  \u001b[38;5;34m1,577,728\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mMultiHeadAttentioâ€¦\u001b[0m â”‚                   â”‚            â”‚ encoder_output[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_128         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_75 (\u001b[38;5;33mAdd\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_128[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚        \u001b[38;5;34m512\u001b[0m â”‚ add_75[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sequential_21       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚    \u001b[38;5;34m525,568\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mSequential\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_130         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sequential_21[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_76 (\u001b[38;5;33mAdd\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dropout_130[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚        \u001b[38;5;34m512\u001b[0m â”‚ add_76[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,440,448</span> (70.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,440,448\u001b[0m (70.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,440,448</span> (70.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,440,448\u001b[0m (70.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoder = build_decoder(vocab_size=input_vocab_size,\n",
    "                        max_len=max_len,\n",
    "                        d_model = 256,\n",
    "                        num_heads= 6,\n",
    "                        num_layers= 5)\n",
    "\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3027c5",
   "metadata": {},
   "source": [
    "----------\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1ad714",
   "metadata": {},
   "source": [
    "## ğŸ¯ Encoder + Decoder birleÅŸimiyle tam bir Transformer modeli kuruyoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a631ad1",
   "metadata": {},
   "source": [
    "Bu, eÄŸitimde kullanÄ±lacak olan \"tam model\" olacak.\n",
    "\n",
    "* Encoder input â†’ Encoder\n",
    "\n",
    "* Decoder input â†’ Decoder\n",
    "\n",
    "Son olarak:\n",
    "\n",
    "* Decoder'Ä±n Ã§Ä±ktÄ±sÄ± â†’ Dense(vocab_size) â†’ tahmin edilen kelime dizis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9540598f",
   "metadata": {},
   "source": [
    "### ğŸ§± 1ï¸âƒ£ build_transformer() Fonksiyonu ğŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54f9152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transformer(input_vocab_size,target_vocab_size,max_len,d_model,num_heads,num_layers,dp=0.3):\n",
    "    \n",
    "    encoder_inputs = layers.Input(shape=(None,) ,name=\"encoder_inputs\")\n",
    "    decoder_inputs = layers.Input(shape=(None,) ,name =\"decoder_inputs\")\n",
    "\n",
    "    encoder = build_encoder(input_vocab_size,max_len,d_model,num_heads,num_layers,dp)\n",
    "    decoder = build_decoder(target_vocab_size,max_len,d_model,num_heads,num_layers,dp)\n",
    "\n",
    "    enc_output = encoder(encoder_inputs)\n",
    "    dec_output = decoder([decoder_inputs,enc_output])\n",
    "\n",
    "    final_outputs = layers.Dense(target_vocab_size,activation=\"softmax\" , name=\"output_layer\")(dec_output)\n",
    "\n",
    "    return Model(inputs=[encoder_inputs,decoder_inputs],outputs =final_outputs , name=\"TransformerModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454fef62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"TransformerModel\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"TransformerModel\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ encoder_inputs      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_inputs      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ TransformerEncoder  â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,591,808</span> â”‚ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ TransformerDecoder  â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,648,064</span> â”‚ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ TransformerEncodâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output_layer        â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)     â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,740</span> â”‚ TransformerDecodâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ encoder_inputs      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_inputs      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ TransformerEncoder  â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚  \u001b[38;5;34m1,591,808\u001b[0m â”‚ encoder_inputs[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ TransformerDecoder  â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚  \u001b[38;5;34m2,648,064\u001b[0m â”‚ decoder_inputs[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ TransformerEncodâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output_layer        â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)     â”‚      \u001b[38;5;34m7,740\u001b[0m â”‚ TransformerDecodâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,247,612</span> (16.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,247,612\u001b[0m (16.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,247,612</span> (16.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,247,612\u001b[0m (16.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transformer = build_transformer(\n",
    "    input_vocab_size=60,\n",
    "    target_vocab_size=60,\n",
    "    max_len=max_len,\n",
    "    d_model=128,\n",
    "    num_heads=4,\n",
    "    num_layers=4\n",
    ")\n",
    "transformer.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e207d5",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c03d9e",
   "metadata": {},
   "source": [
    "# âš™ï¸ Loss + optimizer fonksiyonlarÄ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d84aea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = SparseCategoricalCrossentropy(from_logits=False, reduction='none')\n",
    "\n",
    "def loss_function(y_true, y_pred):\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), dtype=tf.float32)\n",
    "    loss = loss_object(y_true, y_pred)\n",
    "    loss *= mask\n",
    "    return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
    "\n",
    "optimizer = Adam(learning_rate=1e-4)\n",
    "\n",
    "# ğŸ”§ Modeli compile et\n",
    "transformer.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432b3d9b",
   "metadata": {},
   "source": [
    "--------\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddc23b9",
   "metadata": {},
   "source": [
    "## MODEL TANIMLAMALARI Ä°Ã‡Ä°N BÃœTÃœN KODLAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdf1057",
   "metadata": {},
   "source": [
    "### ğŸ”§ 1ï¸âƒ£ encoder_block + build_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df58b121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_block(x, d_model, num_heads, dropout_rate=0.4):\n",
    "    attn_output = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(x, x)\n",
    "    x = add_and_norm(x, attn_output, dp=dropout_rate)\n",
    "\n",
    "    ffn = tf.keras.Sequential([\n",
    "        layers.Dense(d_model * 5, activation='relu'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(d_model)\n",
    "    ])\n",
    "    ffn_output = ffn(x)\n",
    "    x = add_and_norm(x, ffn_output, dp=dropout_rate)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_encoder(vocab_size, max_len, d_model, num_heads, num_layers=3, dropout_rate=0.4):\n",
    "    encoder_inputs = layers.Input(shape=(None,), name=\"encoder_input\")\n",
    "\n",
    "    embedding_layer = token_and_position_embedding(vocab_size, max_len, d_model)\n",
    "    x = embedding_layer(encoder_inputs)\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        x = encoder_block(x, d_model, num_heads, dropout_rate)\n",
    "\n",
    "    return Model(inputs=encoder_inputs, outputs=x, name=\"TransformerEncoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075281e1",
   "metadata": {},
   "source": [
    "### ğŸ”§ 2ï¸âƒ£ decoder_block + build_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "187c2adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(x, enc_output, d_model, num_heads, dropout_rate=0.4):\n",
    "    attn1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(x, x)\n",
    "    x = add_and_norm(x, attn1, dp=dropout_rate)\n",
    "\n",
    "    attn2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(x, enc_output)\n",
    "    x = add_and_norm(x, attn2, dp=dropout_rate)\n",
    "\n",
    "    ffn = tf.keras.Sequential([\n",
    "        layers.Dense(d_model * 5, activation='relu'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(d_model)\n",
    "    ])\n",
    "    ffn_output = ffn(x)\n",
    "    x = add_and_norm(x, ffn_output, dp=dropout_rate)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_decoder(vocab_size, max_len, d_model, num_heads, num_layers=4, dropout_rate=0.4):\n",
    "    decoder_inputs = layers.Input(shape=(None,), name=\"decoder_input\")\n",
    "    encoder_outputs = layers.Input(shape=(None, d_model), name=\"encoder_output\")\n",
    "\n",
    "    embedding_layer = token_and_position_embedding(vocab_size, max_len, d_model)\n",
    "    x = embedding_layer(decoder_inputs)\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        x = decoder_block(x, encoder_outputs, d_model, num_heads, dropout_rate)\n",
    "\n",
    "    return Model(inputs=[decoder_inputs, encoder_outputs], outputs=x, name=\"TransformerDecoder\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081a94b0",
   "metadata": {},
   "source": [
    "### ğŸ§± 3ï¸âƒ£ build_transformer (Encoder + Decoder BirleÅŸimi)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f365dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transformer(input_vocab_size, target_vocab_size, max_len, d_model, num_heads, num_layers=4, dropout_rate=0.4):\n",
    "    encoder_inputs = layers.Input(shape=(None,), name=\"encoder_inputs\")\n",
    "    decoder_inputs = layers.Input(shape=(None,), name=\"decoder_inputs\")\n",
    "\n",
    "    encoder = build_encoder(input_vocab_size, max_len, d_model, num_heads, num_layers, dropout_rate)\n",
    "    decoder = build_decoder(target_vocab_size, max_len, d_model, num_heads, num_layers, dropout_rate)\n",
    "\n",
    "    enc_output = encoder(encoder_inputs)\n",
    "    dec_output = decoder([decoder_inputs, enc_output])\n",
    "\n",
    "    final_output = layers.Dense(target_vocab_size, activation=\"softmax\", name=\"output_layer\")(dec_output)\n",
    "\n",
    "    return Model(inputs=[encoder_inputs, decoder_inputs], outputs=final_output, name=\"TransformerModel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c443aa",
   "metadata": {},
   "source": [
    "#### ğŸ“Œ Ã–rnek Ã‡aÄŸÄ±rma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9f6e070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"TransformerModel\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"TransformerModel\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ encoder_inputs      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_inputs      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ TransformerEncoder  â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">10,286,592</span> â”‚ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ TransformerDecoder  â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">16,637,696</span> â”‚ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ TransformerEncodâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output_layer        â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">251</span>)    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">64,507</span> â”‚ TransformerDecodâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ encoder_inputs      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_inputs      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ TransformerEncoder  â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚ \u001b[38;5;34m10,286,592\u001b[0m â”‚ encoder_inputs[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ TransformerDecoder  â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚ \u001b[38;5;34m16,637,696\u001b[0m â”‚ decoder_inputs[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ TransformerEncodâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output_layer        â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m251\u001b[0m)    â”‚     \u001b[38;5;34m64,507\u001b[0m â”‚ TransformerDecodâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,988,795</span> (102.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m26,988,795\u001b[0m (102.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,988,795</span> (102.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26,988,795\u001b[0m (102.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "target_vocab_size = len(target_tokenizer.word_index) + 1\n",
    "\n",
    "transformer = build_transformer(\n",
    "    input_vocab_size=input_vocab_size,\n",
    "    target_vocab_size=target_vocab_size,\n",
    "    max_len=max_len,\n",
    "    d_model=256,\n",
    "    num_heads=4,\n",
    "    num_layers=6,\n",
    "    dropout_rate=0.4\n",
    ")\n",
    "\n",
    "transformer.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df774828",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = SparseCategoricalCrossentropy(from_logits=False, reduction='none')\n",
    "\n",
    "def loss_function(y_true, y_pred):\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), dtype=tf.float32)\n",
    "    loss = loss_object(y_true, y_pred)\n",
    "    loss *= mask\n",
    "    return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
    "\n",
    "optimizer = Adam(learning_rate=1e-4)\n",
    "\n",
    "# ğŸ”§ Modeli compile et\n",
    "transformer.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39666389",
   "metadata": {},
   "source": [
    "------\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5229a24e",
   "metadata": {},
   "source": [
    "# Åimdi de EÄŸitim ZamanÄ±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ae3117",
   "metadata": {},
   "source": [
    "* Model sonucuna takÄ±lmayÄ±n arkadaÅŸlar.Veri seti 1. aÅŸama olarak 50 veriden oluÅŸuyor ki bu zaten Ã¶ÄŸrenme konusunda hiÃ§bir fayda saÄŸlamaz.Biz burada temel yapÄ±larÄ± Ã§alÄ±ÅŸtÄ±k.Modelin sonucu bizi ilgilendirmiyor.Biz burada iÅŸlemleri anlamaya ve teorik olarak oturtmaya Ã§alÄ±ÅŸÄ±yoruz.Ä°lerleyen zamanlarda projeler yapa yapa sonuca doÄŸru gideceÄŸiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b698fb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.0100 - loss: 5.8811 - val_accuracy: 0.0833 - val_loss: 6.6894\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 665ms/step - accuracy: 0.0812 - loss: 5.5551 - val_accuracy: 0.0833 - val_loss: 6.7695\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 688ms/step - accuracy: 0.0833 - loss: 5.4373 - val_accuracy: 0.0833 - val_loss: 5.7509\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 678ms/step - accuracy: 0.0721 - loss: 5.3819 - val_accuracy: 0.0833 - val_loss: 5.5772\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 671ms/step - accuracy: 0.0741 - loss: 5.4143 - val_accuracy: 0.0833 - val_loss: 5.6213\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 662ms/step - accuracy: 0.0779 - loss: 5.3910 - val_accuracy: 0.0833 - val_loss: 5.7628\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 708ms/step - accuracy: 0.0830 - loss: 5.2922 - val_accuracy: 0.0833 - val_loss: 5.7985\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 709ms/step - accuracy: 0.0812 - loss: 5.2403 - val_accuracy: 0.0833 - val_loss: 5.7230\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 731ms/step - accuracy: 0.0788 - loss: 5.1795 - val_accuracy: 0.0833 - val_loss: 5.6535\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 703ms/step - accuracy: 0.0854 - loss: 5.2014 - val_accuracy: 0.0833 - val_loss: 5.6431\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 710ms/step - accuracy: 0.0821 - loss: 5.2418 - val_accuracy: 0.0833 - val_loss: 5.6691\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 745ms/step - accuracy: 0.0833 - loss: 5.1543 - val_accuracy: 0.0833 - val_loss: 5.7014\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 705ms/step - accuracy: 0.0875 - loss: 5.1567 - val_accuracy: 0.0833 - val_loss: 5.7177\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 787ms/step - accuracy: 0.0854 - loss: 5.1314 - val_accuracy: 0.0833 - val_loss: 5.7380\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 707ms/step - accuracy: 0.0825 - loss: 5.1747 - val_accuracy: 0.0833 - val_loss: 5.7295\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 741ms/step - accuracy: 0.0800 - loss: 5.1950 - val_accuracy: 0.0833 - val_loss: 5.7154\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 717ms/step - accuracy: 0.0858 - loss: 5.1302 - val_accuracy: 0.0833 - val_loss: 5.7096\n",
      "Epoch 18/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 766ms/step - accuracy: 0.0833 - loss: 5.1256 - val_accuracy: 0.0833 - val_loss: 5.7165\n",
      "Epoch 19/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 711ms/step - accuracy: 0.0758 - loss: 5.1717 - val_accuracy: 0.0833 - val_loss: 5.7529\n",
      "Epoch 20/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 770ms/step - accuracy: 0.0825 - loss: 5.0968 - val_accuracy: 0.0833 - val_loss: 5.7703\n",
      "Epoch 21/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 825ms/step - accuracy: 0.0842 - loss: 5.0977 - val_accuracy: 0.0833 - val_loss: 5.7829\n",
      "Epoch 22/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 814ms/step - accuracy: 0.0825 - loss: 5.0824 - val_accuracy: 0.0833 - val_loss: 5.7920\n",
      "Epoch 23/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 861ms/step - accuracy: 0.0884 - loss: 5.0954 - val_accuracy: 0.0833 - val_loss: 5.7891\n",
      "Epoch 24/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 796ms/step - accuracy: 0.0854 - loss: 5.0726 - val_accuracy: 0.0833 - val_loss: 5.7923\n",
      "Epoch 25/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 892ms/step - accuracy: 0.0854 - loss: 5.0247 - val_accuracy: 0.0833 - val_loss: 5.8152\n",
      "Epoch 26/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 776ms/step - accuracy: 0.0779 - loss: 5.1049 - val_accuracy: 0.1167 - val_loss: 5.8472\n",
      "Epoch 27/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 850ms/step - accuracy: 0.0846 - loss: 5.0280 - val_accuracy: 0.1333 - val_loss: 5.8684\n",
      "Epoch 28/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 695ms/step - accuracy: 0.0900 - loss: 5.0207 - val_accuracy: 0.1167 - val_loss: 5.8865\n",
      "Epoch 29/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 702ms/step - accuracy: 0.0879 - loss: 4.9800 - val_accuracy: 0.0833 - val_loss: 5.9019\n",
      "Epoch 30/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 725ms/step - accuracy: 0.0875 - loss: 4.9678 - val_accuracy: 0.0833 - val_loss: 5.9180\n",
      "Epoch 31/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 717ms/step - accuracy: 0.0858 - loss: 5.0065 - val_accuracy: 0.0833 - val_loss: 5.9497\n",
      "Epoch 32/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 700ms/step - accuracy: 0.0879 - loss: 5.0127 - val_accuracy: 0.0833 - val_loss: 5.9693\n",
      "Epoch 33/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 704ms/step - accuracy: 0.0900 - loss: 4.9863 - val_accuracy: 0.1000 - val_loss: 6.0291\n",
      "Epoch 34/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 766ms/step - accuracy: 0.0972 - loss: 4.9617 - val_accuracy: 0.1000 - val_loss: 6.1007\n",
      "Epoch 35/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 719ms/step - accuracy: 0.0888 - loss: 5.0149 - val_accuracy: 0.1167 - val_loss: 6.1161\n",
      "Epoch 36/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 853ms/step - accuracy: 0.0854 - loss: 4.9528 - val_accuracy: 0.1167 - val_loss: 6.0711\n",
      "Epoch 37/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 730ms/step - accuracy: 0.0875 - loss: 4.9214 - val_accuracy: 0.1500 - val_loss: 6.0086\n",
      "Epoch 38/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 720ms/step - accuracy: 0.0951 - loss: 4.9469 - val_accuracy: 0.1500 - val_loss: 6.0191\n",
      "Epoch 39/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 750ms/step - accuracy: 0.0914 - loss: 4.9539 - val_accuracy: 0.1333 - val_loss: 6.0914\n",
      "Epoch 40/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 734ms/step - accuracy: 0.0909 - loss: 4.9691 - val_accuracy: 0.1167 - val_loss: 6.1602\n",
      "Epoch 41/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 705ms/step - accuracy: 0.0963 - loss: 4.9860 - val_accuracy: 0.1000 - val_loss: 6.1798\n",
      "Epoch 42/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 704ms/step - accuracy: 0.0930 - loss: 4.8987 - val_accuracy: 0.1000 - val_loss: 6.1814\n",
      "Epoch 43/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 772ms/step - accuracy: 0.0917 - loss: 4.9326 - val_accuracy: 0.1000 - val_loss: 6.1571\n",
      "Epoch 44/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 671ms/step - accuracy: 0.1051 - loss: 4.9195 - val_accuracy: 0.0833 - val_loss: 6.1429\n",
      "Epoch 45/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 723ms/step - accuracy: 0.0930 - loss: 4.8817 - val_accuracy: 0.1000 - val_loss: 6.1758\n",
      "Epoch 46/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 708ms/step - accuracy: 0.0997 - loss: 4.8547 - val_accuracy: 0.1000 - val_loss: 6.2019\n",
      "Epoch 47/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 694ms/step - accuracy: 0.1023 - loss: 4.8523 - val_accuracy: 0.1000 - val_loss: 6.2580\n",
      "Epoch 48/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 694ms/step - accuracy: 0.1014 - loss: 4.8196 - val_accuracy: 0.1333 - val_loss: 6.3275\n",
      "Epoch 49/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 782ms/step - accuracy: 0.1005 - loss: 4.8205 - val_accuracy: 0.1333 - val_loss: 6.3667\n",
      "Epoch 50/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 816ms/step - accuracy: 0.0972 - loss: 4.8262 - val_accuracy: 0.1500 - val_loss: 6.3639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2ae90799820>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.fit(\n",
    "    [encoder_input, decoder_input],\n",
    "    decoder_target,\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    validation_split=0.1  # istersen\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804c775e",
   "metadata": {},
   "source": [
    "------\n",
    "------\n",
    "\n",
    "## Åimdi Modeli Deneyelim\n",
    "\n",
    "-------\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7438ed63",
   "metadata": {},
   "source": [
    "### âœ… 1ï¸âƒ£ evaluate_sentence() Fonksiyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cecf78d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sentence(sentence, tokenizer_in, tokenizer_out, transformer, max_len):\n",
    "    # 1. Girdiyi tokenize et\n",
    "    input_seq = tokenizer_in.texts_to_sequences([sentence])\n",
    "    encoder_input = pad_sequences(input_seq, maxlen=max_len, padding='post')\n",
    "\n",
    "    # 2. Decoder'Ä± <start> token ile baÅŸlat\n",
    "    start_token = tokenizer_out.word_index.get('<start>', 1)\n",
    "    end_token = tokenizer_out.word_index.get('<end>', 2)\n",
    "\n",
    "    decoder_input = [start_token]\n",
    "    result = []\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        # Padle\n",
    "        dec_in = pad_sequences([decoder_input], maxlen=max_len, padding='post')\n",
    "\n",
    "        # Model tahmini\n",
    "        predictions = transformer.predict([encoder_input, dec_in], verbose=0)\n",
    "        predicted_id = tf.argmax(predictions[0, len(decoder_input)-1]).numpy()\n",
    "\n",
    "        # <end> geldiyse dur\n",
    "        if predicted_id == end_token:\n",
    "            break\n",
    "\n",
    "        result.append(predicted_id)\n",
    "        decoder_input.append(predicted_id)\n",
    "\n",
    "    # ID â†’ kelime Ã§evir\n",
    "    reverse_target_word_index = {i: w for w, i in tokenizer_out.word_index.items()}\n",
    "    predicted_sentence = ' '.join([reverse_target_word_index.get(i, '?') for i in result])\n",
    "\n",
    "    return predicted_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9c2609",
   "metadata": {},
   "source": [
    "#### ğŸ“Œ KullanÄ±mÄ±:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c9680811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: bir bir bir bir\n"
     ]
    }
   ],
   "source": [
    "test_input = \"Merhaba\"\n",
    "output = evaluate_sentence(test_input, input_tokenizer, target_tokenizer, transformer, max_len=max_len)\n",
    "print(\"Bot:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0a357f",
   "metadata": {},
   "source": [
    "------\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee11c32b",
   "metadata": {},
   "source": [
    "# ğŸ§  MASKING â€“ Transformerâ€™da Ne Ä°ÅŸe Yarar?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c26e1c",
   "metadata": {},
   "source": [
    "#### Transformer paralel Ã§alÄ±ÅŸtÄ±ÄŸÄ± iÃ§in:\n",
    "\n",
    "* TÃ¼m cÃ¼mle bir anda iÅŸlenir\n",
    "\n",
    "Ama bazÄ± yerleri gizlemek gerekir:\n",
    "\n",
    "* PAD tokenlarÄ± (eÄŸitimi bozmasÄ±n diye)\n",
    "\n",
    "* Decoder'da gelecekteki kelimeler (daha yazÄ±lmamÄ±ÅŸsa bakmamalÄ±)\n",
    "\n",
    "Ä°ÅŸte bu durumda devreye \"masking\" girer âœ…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b84be8",
   "metadata": {},
   "source": [
    "## ğŸ­ MASKING TÃœRLERÄ°\n",
    "#### 1ï¸âƒ£ Padding Mask (GerÃ§ek cÃ¼mle â‰  pad token)\n",
    "\n",
    "* PAD token'lar model iÃ§in bilgi taÅŸÄ±maz\n",
    "\n",
    "* Hem encoder hem decoder'da kullanÄ±lÄ±r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516ab669",
   "metadata": {},
   "source": [
    "CÃ¼mle:      merhaba nasÄ±lsÄ±n <pad <pad\n",
    "\n",
    "Mask:       1          1         0     0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4f57ac",
   "metadata": {},
   "source": [
    "### 2ï¸âƒ£ Look-Ahead Mask (Causal Masking)\n",
    "* Decoder kendinden sonraki kelimeye bakamaz\n",
    "\n",
    "* Ã‡Ã¼nkÃ¼ henÃ¼z yazÄ±lmamÄ±ÅŸtÄ±r\n",
    "\n",
    "* Yani decoder_input[t] â†’ sadece [:t]â€™ye kadar bakar\n",
    "\n",
    "Ã–rn (3 kelime iÃ§in):\n",
    "\n",
    "1 0 0\n",
    "\n",
    "1 1 0\n",
    "\n",
    "1 1 1\n",
    "\n",
    "* Bu bir Ã¼st Ã¼Ã§gen matris'tir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada28603",
   "metadata": {},
   "source": [
    "### 3ï¸âƒ£ Combined Mask\n",
    "* Padding + look-ahead birlikte\n",
    "\n",
    "* Decoderâ€™Ä±n hem padâ€™leri hem geleceÄŸi gÃ¶rmemesini saÄŸlar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1248816e",
   "metadata": {},
   "source": [
    "## ğŸ”§ Nerelerde KullanÄ±lÄ±r?\n",
    "| Maske TÃ¼rÃ¼     | KullanÄ±ldÄ±ÄŸÄ± Yer             |\n",
    "|----------------|-------------------------------|\n",
    "| Padding Mask   | Encoder & Decoder Attention   |\n",
    "| Look-Ahead     | Decoder Self-Attention        |\n",
    "| Combined Mask  | Decoderâ€™Ä±n giriÅŸ kÄ±smÄ±nda     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dc9838",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Neden Bu Kadar Ã–nemli?\n",
    "âŒ EÄŸer mask yapÄ±lmazsa:\n",
    "\n",
    "* Pad tokenâ€™lar sÄ±fÄ±r olduÄŸu halde Ã¶ÄŸrenme hatasÄ± oluÅŸur\n",
    "\n",
    "* Decoder ilerideki kelimeyi gÃ¶rerek â€œhile yaparâ€\n",
    "\n",
    "âœ… Mask â†’ DoÄŸru Ã¶ÄŸrenmeyi garanti eder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed395e53",
   "metadata": {},
   "source": [
    "\n",
    "### Ama asÄ±l kritik soru ÅŸu:\n",
    "âš™ï¸ \"Transformerâ€™Ä±n neresine bu maskâ€™leri enjekte edeceÄŸiz?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b77c55d",
   "metadata": {},
   "source": [
    "## ğŸ§  Ã–zet: Masking'i Nerede KullanÄ±yoruz?\n",
    "\n",
    "| Nerede?                       | Ne Veriyoruz?                   |\n",
    "|-------------------------------|----------------------------------|\n",
    "| ğŸ”¹ Encoder Self-Attention     | `attention_mask = padding_mask` |\n",
    "| ğŸ”¹ Decoder Self-Attention     | `attention_mask = combined_mask`|\n",
    "| ğŸ”¹ Decoder Enc-Dec Attention  | `attention_mask = padding_mask` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f606e8",
   "metadata": {},
   "source": [
    "### Åimdi kodlamaya geÃ§elim.Ama unutmayÄ±n.Biz bu mask iÅŸlemlerinin hepsini uyguluyoruz.YalnÄ±zca yukarÄ±da duran kavramlara gÃ¶re yapacaÄŸÄ±z.Yani farklÄ± katmanlara enjekte edeceÄŸiz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9dc0a7",
   "metadata": {},
   "source": [
    "## ğŸ”¹ 1ï¸âƒ£ create_padding_mask() â€“ TEORÄ°\n",
    "Ne yapar?\n",
    "\n",
    "* GiriÅŸ tensÃ¶rÃ¼nde (Ã¶rneÄŸin [5, 7, 0, 0])\n",
    "\n",
    "* 0 olanlarÄ± tespit eder (bunlar <pad>)\n",
    "\n",
    "* BunlarÄ± 1 yapar â†’ yani maskelenecek yer\n",
    "\n",
    "* ArdÄ±ndan True â†’ 1.0, False â†’ 0.0 olarak float mask Ã¼retir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a31ed928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    # PAD token = 0 â†’ True olur\n",
    "    mask = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # [batch, seq_len] â†’ [batch, 1, 1, seq_len]\n",
    "    # Bu, MultiHeadAttention iÃ§in beklenen shapeâ€™tir\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a2dccf",
   "metadata": {},
   "source": [
    "#### ğŸ“Œ Ã–rnek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4983eb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[[0. 0. 1. 1. 1.]]]], shape=(1, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "seq = tf.constant([[7, 6, 0, 0, 0]])\n",
    "mask = create_padding_mask(seq)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51171d61",
   "metadata": {},
   "source": [
    "#### ğŸ” Ã‡Ä±ktÄ±:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a254ae",
   "metadata": {},
   "source": [
    "\n",
    "[[[[0. 0. 1. 1. 1.]]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babe72ae",
   "metadata": {},
   "source": [
    "* Yani 0 olan yerlere dikkat edilmesin dedik âœ…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2219588b",
   "metadata": {},
   "source": [
    "## ğŸ”¹ 2ï¸âƒ£ create_look_ahead_mask() â€“ TEORÄ°\n",
    "AmaÃ§:\n",
    "\n",
    "* Decoder kendi cÃ¼mlesini Ã¼retirken gelecekteki kelimelere bakmamalÄ±\n",
    "\n",
    "* Yani t=3 anÄ±ndayken sadece 0, 1, 2 pozisyonlarÄ±nÄ± gÃ¶rmeli\n",
    "\n",
    "* Bu, causal (nedensel) attention saÄŸlar â†’ kelime sÄ±rasÄ±na sadÄ±k kalÄ±nÄ±r âœ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4ded9763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    # tf.ones((size, size)) â†’ [size x size] boyutunda sadece 1'lerden oluÅŸan matris Ã¼retir\n",
    "    # Ã–rn: size=4 ise â†’ [[1 1 1 1], [1 1 1 1], [1 1 1 1], [1 1 1 1]]\n",
    "\n",
    "    # tf.linalg.band_part(tensor, num_lower, num_upper):\n",
    "    # - 'band_part' fonksiyonu matrisi Ã¼Ã§gen hale getirir\n",
    "    # - num_lower=-1 â†’ alttaki tÃ¼m satÄ±rlarÄ± tut\n",
    "    # - num_upper=0  â†’ sadece diagonal ve alt taraf kalÄ±r, Ã¼st kÄ±smÄ± sÄ±fÄ±rlar\n",
    "\n",
    "    # tf.linalg.band_part(tf.ones(...), -1, 0)\n",
    "    # â†’ Alt Ã¼Ã§gen matris Ã¼retir:\n",
    "    # [[1 0 0 0]\n",
    "    #  [1 1 0 0]\n",
    "    #  [1 1 1 0]\n",
    "    #  [1 1 1 1]]\n",
    "\n",
    "    # 1 - (...) â†’ Ã¼st Ã¼Ã§geni 1 yapar:\n",
    "    # [[0 1 1 1]\n",
    "    #  [0 0 1 1]\n",
    "    #  [0 0 0 1]\n",
    "    #  [0 0 0 0]]\n",
    "\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "\n",
    "    return mask  # shape: [size, size]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e94aa59",
   "metadata": {},
   "source": [
    "### ğŸ“Œ Ã–rnek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "20e5d6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0.]], shape=(5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "mask = create_look_ahead_mask(5)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7af2953",
   "metadata": {},
   "source": [
    "* Yani pozisyon t yalnÄ±zca 0:t aralÄ±ÄŸÄ±nÄ± gÃ¶rebilir.\n",
    "\n",
    "* YukarÄ±sÄ± 1 â†’ gizlenecek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcd2931",
   "metadata": {},
   "source": [
    "## ğŸ”— Combined Mask = Padding Mask + Look-Ahead Mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0310c56",
   "metadata": {},
   "source": [
    "* Bu maskeyi decoderâ€™Ä±n self-attention kÄ±smÄ±nda kullanÄ±yoruz.\n",
    "\n",
    "AmaÃ§:\n",
    "\n",
    "ğŸ”’ GeleceÄŸe bakamasÄ±n (look-ahead)\n",
    "\n",
    "ğŸ§¼ Pad token'lara dikkat etmesin (padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d9af30",
   "metadata": {},
   "source": [
    "### ğŸ§  Neden Combine Ediyoruz?\n",
    "* Tek baÅŸÄ±na look_ahead_mask:\n",
    "\n",
    "Sadece geleceÄŸi gizler, ama padâ€™leri gÃ¶rÃ¼r âŒ\n",
    "\n",
    "* Tek baÅŸÄ±na padding_mask:\n",
    "\n",
    "Padâ€™leri gizler, ama geleceÄŸe bakar âŒ\n",
    "\n",
    "* BunlarÄ± tf.maximum() ile birleÅŸtirince:\n",
    "\n",
    "Neresi 1 ise orayÄ± gizle â†’ hem pad hem gelecek âœ”ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "44613355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_mask(decoder_input):\n",
    "\n",
    "    look_ahead = create_look_ahead_mask(tf.shape(decoder_input)[1])\n",
    "\n",
    "    padding = create_padding_mask(decoder_input)\n",
    "\n",
    "    look_ahead = tf.maximum(look_ahead,padding[:,:,0:])\n",
    "\n",
    "    return look_ahead[:,tf.newaxis,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0803c0db",
   "metadata": {},
   "source": [
    "### YukarÄ±da bulunan kodlarla temel masking bilgisini anlatmaya Ã§alÄ±ÅŸtÄ±m.Åimdi bunlarÄ± nasÄ±l modele aktaracaÄŸÄ±mÄ±za bakalÄ±m."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dac5027",
   "metadata": {},
   "source": [
    "----\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284a02a9",
   "metadata": {},
   "source": [
    "## HazÄ±rladÄ±ÄŸÄ±mÄ±z padding_mask, look_ahead_mask, combined_mask fonksiyonlarÄ±nÄ±ÅŸimdi encoder_block ve decoder_block'a entegre ediyoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961ab056",
   "metadata": {},
   "source": [
    "### ğŸ§± 1ï¸âƒ£ encoder_block â€“ Mask Eklemesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "da57255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_block(x, d_model, num_heads, dropout_rate, padding_mask=None):\n",
    "    attn_output = MultiHeadAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model\n",
    "    )(x, x, attention_mask=padding_mask)  # Maske burada kullanÄ±lÄ±yor\n",
    "\n",
    "    x = add_and_norm(x, attn_output, dp=dropout_rate)\n",
    "\n",
    "    ffn = tf.keras.Sequential([\n",
    "        Dense(d_model * 4, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(d_model)\n",
    "    ])\n",
    "    ffn_output = ffn(x)\n",
    "    x = add_and_norm(x, ffn_output, dp=dropout_rate)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac69d6d",
   "metadata": {},
   "source": [
    "### ğŸ”§ 1ï¸âƒ£ build_encoder() â€“ Mask Entegreli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d6bf8073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder(vocab_size, max_len, d_model, num_heads, num_layers=1, dropout_rate=0.1):\n",
    "    encoder_inputs = Input(shape=(None,), name=\"encoder_input\")\n",
    "\n",
    "    embedding_layer = token_and_position_embedding(vocab_size, max_len, d_model)\n",
    "    x = embedding_layer(encoder_inputs)\n",
    "\n",
    "    # Padding mask (mask shape: [batch, 1, 1, seq_len])\n",
    "    padding_mask = Lambda(lambda seq: create_padding_mask(seq))(encoder_inputs)\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        x = encoder_block(x, d_model, num_heads, dropout_rate, padding_mask=padding_mask)\n",
    "\n",
    "    return Model(inputs=encoder_inputs, outputs=x, name=\"TransformerEncoder\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2327dbc6",
   "metadata": {},
   "source": [
    "### ğŸ” 2ï¸âƒ£ decoder_block â€“ 2 Maske Eklemesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "74197d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(x, enc_output, d_model, num_heads,\n",
    "                  dropout_rate=0.1, combined_mask=None, padding_mask=None):\n",
    "    # 1. Decoder Self-Attention (geleceÄŸi gÃ¶rememeli)\n",
    "    attn1 = MultiHeadAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model\n",
    "    )(x, x, attention_mask=combined_mask)  # âœ… Look-Ahead + Padding mask\n",
    "\n",
    "    x = add_and_norm(x, attn1, dp=dropout_rate)\n",
    "\n",
    "    # 2. Encoder-Decoder Attention (pad'leri gizle)\n",
    "    attn2 = MultiHeadAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model\n",
    "    )(x, enc_output, attention_mask=padding_mask)  # âœ… Padding mask\n",
    "\n",
    "    x = add_and_norm(x, attn2, dp=dropout_rate)\n",
    "\n",
    "    # 3. Feed-Forward\n",
    "    ffn = tf.keras.Sequential([\n",
    "        Dense(d_model * 4, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(d_model)\n",
    "    ])\n",
    "    ffn_output = ffn(x)\n",
    "    x = add_and_norm(x, ffn_output, dp=dropout_rate)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dc7dd2",
   "metadata": {},
   "source": [
    "### ğŸ” 2ï¸âƒ£ build_decoder() â€“ Full Mask Entegreli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f0a01c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decoder(vocab_size, max_len, d_model, num_heads, num_layers=1, dropout_rate=0.1):\n",
    "    decoder_inputs = Input(shape=(None,), name=\"decoder_input\")\n",
    "    encoder_outputs = Input(shape=(None, d_model), name=\"encoder_output\")\n",
    "\n",
    "    embedding_layer = token_and_position_embedding(vocab_size, max_len, d_model)\n",
    "    x = embedding_layer(decoder_inputs)\n",
    "\n",
    "    # Maskleri oluÅŸtur\n",
    "    padding_mask = Lambda(lambda seq: create_padding_mask(seq))(decoder_inputs)\n",
    "    look_ahead = Lambda(lambda seq: create_look_ahead_mask(tf.shape(seq)[1]))(decoder_inputs)\n",
    "    combined_mask = Lambda(lambda args: tf.maximum(args[0], args[1]))([look_ahead, padding_mask])\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        x = decoder_block(\n",
    "            x,\n",
    "            encoder_outputs,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout_rate,\n",
    "            combined_mask=combined_mask,\n",
    "            padding_mask=padding_mask\n",
    "        )\n",
    "\n",
    "    return Model(inputs=[decoder_inputs, encoder_outputs], outputs=x, name=\"TransformerDecoder\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba438aa8",
   "metadata": {},
   "source": [
    "### ğŸ§± build_transformer() â€“ Mask Entegreli Final SÃ¼rÃ¼m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2733109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transformer(input_vocab_size, target_vocab_size, max_len,\n",
    "                      d_model, num_heads, num_layers=1, dropout_rate=0.1):\n",
    "    \n",
    "    # GiriÅŸler\n",
    "    encoder_inputs = Input(shape=(None,), name=\"encoder_inputs\")\n",
    "    decoder_inputs = Input(shape=(None,), name=\"decoder_inputs\")\n",
    "\n",
    "    # Encoder ve Decoder modellerini oluÅŸtur\n",
    "    encoder = build_encoder(input_vocab_size, max_len, d_model, num_heads, num_layers, dropout_rate)\n",
    "    decoder = build_decoder(target_vocab_size, max_len, d_model, num_heads, num_layers, dropout_rate)\n",
    "\n",
    "    # Encoder output\n",
    "    enc_output = encoder(encoder_inputs)\n",
    "\n",
    "    # Decoder output (encoder output'u da alÄ±r)\n",
    "    dec_output = decoder([decoder_inputs, enc_output])\n",
    "\n",
    "    # Final Dense layer: her timestep'te vocab boyutunda softmax\n",
    "    final_output = Dense(target_vocab_size, activation='softmax', name=\"output_layer\")(dec_output)\n",
    "\n",
    "    # Modeli tanÄ±mla\n",
    "    return Model(inputs=[encoder_inputs, decoder_inputs], outputs=final_output, name=\"TransformerModel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "73842d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"TransformerModel\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"TransformerModel\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ encoder_inputs      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_inputs      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ TransformerEncoder  â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,763,136</span> â”‚ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ TransformerDecoder  â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,956,992</span> â”‚ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ TransformerEncodâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output_layer        â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">251</span>)    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">64,507</span> â”‚ TransformerDecodâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ encoder_inputs      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_inputs      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ TransformerEncoder  â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚  \u001b[38;5;34m4,763,136\u001b[0m â”‚ encoder_inputs[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ TransformerDecoder  â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚  \u001b[38;5;34m7,956,992\u001b[0m â”‚ decoder_inputs[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ TransformerEncodâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output_layer        â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m251\u001b[0m)    â”‚     \u001b[38;5;34m64,507\u001b[0m â”‚ TransformerDecodâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,784,635</span> (48.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,784,635\u001b[0m (48.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,784,635</span> (48.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,784,635\u001b[0m (48.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transformer = build_transformer(\n",
    "    input_vocab_size=input_vocab_size,\n",
    "    target_vocab_size=target_vocab_size,\n",
    "    max_len=max_len,\n",
    "    d_model=256,\n",
    "    num_heads=4,\n",
    "    num_layers=3,\n",
    "    dropout_rate=0.5\n",
    ")\n",
    "transformer.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ed2551",
   "metadata": {},
   "source": [
    "### âœ… 1ï¸âƒ£ Loss Fonksiyonu â€“ PAD maskeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "be0b86d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=False,\n",
    "    reduction='none'  # PAD iÃ§in maskeleme uygulayacaÄŸÄ±z\n",
    ")\n",
    "\n",
    "def loss_function(y_true, y_pred):\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)  # PAD'ler 0'dÄ±r â†’ onlarÄ± dÄ±ÅŸla\n",
    "    loss = loss_object(y_true, y_pred)\n",
    "    loss *= mask\n",
    "    return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99867d4f",
   "metadata": {},
   "source": [
    "### âš™ï¸ 2ï¸âƒ£ Optimizer - Compile Et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bd513067",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "transformer.compile(loss=loss_function, optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68779eda",
   "metadata": {},
   "source": [
    "### ğŸ“¦ 4ï¸âƒ£ EÄŸitime BaÅŸla (fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "322de4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.0012 - loss: 5.9597 - val_accuracy: 0.0833 - val_loss: 5.6882\n",
      "Epoch 2/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 379ms/step - accuracy: 0.0339 - loss: 5.7190 - val_accuracy: 0.0833 - val_loss: 6.4323\n",
      "Epoch 3/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 346ms/step - accuracy: 0.0728 - loss: 5.5923 - val_accuracy: 0.0833 - val_loss: 7.1825\n",
      "Epoch 4/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 364ms/step - accuracy: 0.0833 - loss: 5.4467 - val_accuracy: 0.0833 - val_loss: 7.2245\n",
      "Epoch 5/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 341ms/step - accuracy: 0.0846 - loss: 5.4262 - val_accuracy: 0.0833 - val_loss: 6.7729\n",
      "Epoch 6/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 352ms/step - accuracy: 0.0800 - loss: 5.3585 - val_accuracy: 0.0833 - val_loss: 6.3168\n",
      "Epoch 7/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 352ms/step - accuracy: 0.0842 - loss: 5.3457 - val_accuracy: 0.1167 - val_loss: 6.0718\n",
      "Epoch 8/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 361ms/step - accuracy: 0.0749 - loss: 5.2766 - val_accuracy: 0.1500 - val_loss: 5.9738\n",
      "Epoch 9/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 428ms/step - accuracy: 0.0804 - loss: 5.3280 - val_accuracy: 0.1500 - val_loss: 5.9410\n",
      "Epoch 10/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 417ms/step - accuracy: 0.0674 - loss: 5.3824 - val_accuracy: 0.1333 - val_loss: 5.9640\n",
      "Epoch 11/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 411ms/step - accuracy: 0.0737 - loss: 5.2775 - val_accuracy: 0.1167 - val_loss: 6.0302\n",
      "Epoch 12/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 400ms/step - accuracy: 0.0863 - loss: 5.2653 - val_accuracy: 0.0833 - val_loss: 6.1324\n",
      "Epoch 13/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 397ms/step - accuracy: 0.0791 - loss: 5.2206 - val_accuracy: 0.0833 - val_loss: 6.2359\n",
      "Epoch 14/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 384ms/step - accuracy: 0.0800 - loss: 5.1896 - val_accuracy: 0.0833 - val_loss: 6.2834\n",
      "Epoch 15/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 396ms/step - accuracy: 0.0879 - loss: 5.1529 - val_accuracy: 0.0833 - val_loss: 6.2542\n",
      "Epoch 16/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 397ms/step - accuracy: 0.0909 - loss: 5.2347 - val_accuracy: 0.0833 - val_loss: 6.1930\n",
      "Epoch 17/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 393ms/step - accuracy: 0.0854 - loss: 5.2163 - val_accuracy: 0.0833 - val_loss: 6.1265\n",
      "Epoch 18/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 390ms/step - accuracy: 0.0833 - loss: 5.1164 - val_accuracy: 0.1000 - val_loss: 6.0659\n",
      "Epoch 19/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 386ms/step - accuracy: 0.0896 - loss: 5.1771 - val_accuracy: 0.1167 - val_loss: 6.0321\n",
      "Epoch 20/20\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 400ms/step - accuracy: 0.0854 - loss: 5.1463 - val_accuracy: 0.1167 - val_loss: 6.0416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2af454434d0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.fit(\n",
    "    [encoder_input, decoder_input],\n",
    "    decoder_target,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_split=0.1  # istersen ayÄ±r\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa80f061",
   "metadata": {},
   "source": [
    "-------\n",
    "-----\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ff154c",
   "metadata": {},
   "source": [
    "# Åimdi bÃ¼tÃ¼n bu Ã¶ÄŸrendiÄŸimiz terimleri bir koda geÃ§ireceÄŸiz.Temel yapÄ± taÅŸlarÄ±nÄ± oturttuk ÅŸimdi Ã¶nemli olan bu kodlarÄ± iyice teorikle beraber anlamak.Burda bahsedilmek istenilen kod parÃ§alarÄ±na (( transformer_1_kodlarÄ±.ipynb ))  iÃ§erisinden ulaÅŸabilirsiniz.KarmaÅŸÄ±klÄ±ÄŸÄ± engellemek iÃ§in oradan inceleyiniz.\n",
    "\n",
    "-----\n",
    "--------\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8bbb08",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
