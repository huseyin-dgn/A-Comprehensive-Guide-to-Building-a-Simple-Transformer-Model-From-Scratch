{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de7be645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 TensorFlow ve Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Embedding, Dropout, LayerNormalization,\n",
    "    MultiHeadAttention, Add, Lambda\n",
    ")\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# 🧪 Sıralı bloklar için\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "# 🧠 Tokenizer ve padding için\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 📊 Veri işleme (eğer kullanıyorsan)\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efbdda9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Merhaba</td>\n",
       "      <td>Merhaba, size nasıl yardımcı olabilirim?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nasılsın?</td>\n",
       "      <td>İyiyim, teşekkür ederim. Siz nasılsınız?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adın ne?</td>\n",
       "      <td>Ben bir yapay zekâ asistanıyım. Adım yok ama y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kaç yaşındasın?</td>\n",
       "      <td>Benim yaşım yok, dijitalim!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bugün günlerden ne?</td>\n",
       "      <td>Maalesef tarih bilgim yok, ama sistem saatinde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 input                                             output\n",
       "0              Merhaba           Merhaba, size nasıl yardımcı olabilirim?\n",
       "1            Nasılsın?           İyiyim, teşekkür ederim. Siz nasılsınız?\n",
       "2             Adın ne?  Ben bir yapay zekâ asistanıyım. Adım yok ama y...\n",
       "3      Kaç yaşındasın?                        Benim yaşım yok, dijitalim!\n",
       "4  Bugün günlerden ne?  Maalesef tarih bilgim yok, ama sistem saatinde..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"örnek_set.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ee67491",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = df['input'].astype(str).to_list()\n",
    "target_texts = df['output'].astype(str).to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4500747",
   "metadata": {},
   "source": [
    "### TOKENİZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba595570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Başlangıç ve bitiş token'ları ekle\n",
    "target_texts_in  = ['<start> ' + t for t in target_texts]\n",
    "target_texts_out = [t + ' <end>'    for t in target_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08926a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokenizer  = Tokenizer(oov_token='<OOV>')\n",
    "input_tokenizer.fit_on_texts(input_texts)\n",
    "target_tokenizer = Tokenizer(oov_token='<OOV>')\n",
    "target_tokenizer.fit_on_texts(target_texts_in + target_texts_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "593a0dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seqs  = input_tokenizer.texts_to_sequences(input_texts)\n",
    "decoder_in  = target_tokenizer.texts_to_sequences(target_texts_in)\n",
    "decoder_out = target_tokenizer.texts_to_sequences(target_texts_out)\n",
    "\n",
    "max_len_input  = max(len(seq) for seq in input_seqs)\n",
    "max_len_output = max(len(seq) for seq in decoder_in + decoder_out)\n",
    "max_len        = max(max_len_input, max_len_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f9590b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "237\n"
     ]
    }
   ],
   "source": [
    "encoder_input  = pad_sequences(input_seqs, padding='post', maxlen=max_len)\n",
    "decoder_input  = pad_sequences(decoder_in,   padding='post', maxlen=max_len)\n",
    "decoder_target = pad_sequences(decoder_out,  padding='post', maxlen=max_len)\n",
    "\n",
    "input_vocab_size  = len(input_tokenizer.word_index) + 1\n",
    "target_vocab_size = len(target_tokenizer.word_index) + 1\n",
    "\n",
    "print(input_vocab_size)\n",
    "print(target_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c64b45",
   "metadata": {},
   "source": [
    "#### 📌 2. position_encoding() -- 📌 3. token_and_position_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "987b183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self, max_len, d_model, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        angle_rads = self._get_angles(\n",
    "            np.arange(max_len)[:, np.newaxis],\n",
    "            np.arange(d_model)[np.newaxis, :],\n",
    "            d_model\n",
    "        )\n",
    "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "        self.pos_encoding = tf.constant(angle_rads[np.newaxis, ...], dtype=tf.float32)\n",
    "    def _get_angles(self, pos, i, d_model):\n",
    "        return pos / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    def call(self, x):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        return x + self.pos_encoding[:, :seq_len, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e782212d",
   "metadata": {},
   "source": [
    "### 📌 4. add_and_norm() --- 📌 5. feed_forward_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf88fbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_and_norm(x, sublayer, dp=0.1):\n",
    "    out = Dropout(dp)(sublayer)\n",
    "    out = layers.Add()([x, out])\n",
    "    return LayerNormalization(epsilon=1e-6)(out)\n",
    "\n",
    "def feed_forward_network(d_model):\n",
    "    # Removed explicit name to avoid duplicate naming errors\n",
    "    return Sequential([\n",
    "        layers.Dense(d_model * 4, activation='relu'),\n",
    "        Dropout(0.1),\n",
    "        layers.Dense(d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce73b6d",
   "metadata": {},
   "source": [
    "-------\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb7a65d",
   "metadata": {},
   "source": [
    "### ✅  Mask Fonksiyonu – Toplu Kod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3123b600",
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_mask_layer = Lambda(\n",
    "    lambda seq: tf.cast(tf.math.equal(seq, 0), tf.float32)[:, tf.newaxis, tf.newaxis, :],\n",
    "    name=\"padding_mask\"\n",
    ")\n",
    "\n",
    "def combined_mask_layer(seq):\n",
    "    seq_len = tf.shape(seq)[1]\n",
    "    pad     = tf.cast(tf.math.equal(seq, 0), tf.float32)[:, tf.newaxis, tf.newaxis, :]\n",
    "    look    = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    look    = look[tf.newaxis, tf.newaxis, :, :]\n",
    "    return tf.maximum(pad, look)\n",
    "\n",
    "combined_mask_layer = Lambda(combined_mask_layer, name=\"combined_mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ae1524",
   "metadata": {},
   "source": [
    "-----\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cb5591",
   "metadata": {},
   "source": [
    "### 📌 6. encoder_block()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a261473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_block(x, d_model, num_heads, dp, mask):\n",
    "    attn = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(x, x, attention_mask=mask)\n",
    "    x1   = add_and_norm(x, attn, dp)\n",
    "    ffn  = feed_forward_network(d_model)(x1)\n",
    "    return add_and_norm(x1, ffn, dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c820c9",
   "metadata": {},
   "source": [
    "### 📌 7. decoder_block()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe7cd150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(x, enc_out, d_model, num_heads, dp, look_mask, pad_mask):\n",
    "    attn1 = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(x, x, attention_mask=look_mask)\n",
    "    x1    = add_and_norm(x, attn1, dp)\n",
    "    attn2 = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(x1, enc_out, attention_mask=pad_mask)\n",
    "    x2    = add_and_norm(x1, attn2, dp)\n",
    "    ffn   = feed_forward_network(d_model)(x2)\n",
    "    return add_and_norm(x2, ffn, dp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193aaf45",
   "metadata": {},
   "source": [
    "### 📌 8. build_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4467017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder(vocab_size, max_len, d_model, num_heads, num_layers, dp):\n",
    "    inp  = Input(shape=(None,), name='encoder_input')\n",
    "    mask = padding_mask_layer(inp)\n",
    "    x    = Embedding(vocab_size, d_model)(inp)\n",
    "    x    = PositionalEncoding(max_len, d_model)(x)\n",
    "    for _ in range(num_layers):\n",
    "        x = encoder_block(x, d_model, num_heads, dp, mask)\n",
    "    return Model(inputs=inp, outputs=x, name='TransformerEncoder')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f736116f",
   "metadata": {},
   "source": [
    "### 📌 9. build_decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96e70a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decoder(vocab_size, max_len, d_model, num_heads, num_layers, dp):\n",
    "    dec_in  = Input(shape=(None,), name='decoder_input')\n",
    "    enc_out = Input(shape=(None, d_model), name='encoder_output')\n",
    "    look    = combined_mask_layer(dec_in)\n",
    "    pad     = padding_mask_layer(dec_in)\n",
    "    x       = Embedding(vocab_size, d_model)(dec_in)\n",
    "    x       = PositionalEncoding(max_len, d_model)(x)\n",
    "    for _ in range(num_layers):\n",
    "        x = decoder_block(x, enc_out, d_model, num_heads, dp, look, pad)\n",
    "    return Model(inputs=[dec_in, enc_out], outputs=x, name='TransformerDecoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7d9919",
   "metadata": {},
   "source": [
    "### 📌 10. build_transformer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db85aa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transformer(in_vocab, tar_vocab, max_len, d_model, num_heads, num_layers, dp):\n",
    "    enc_inputs = Input(shape=(None,), name='encoder_inputs')\n",
    "    dec_inputs = Input(shape=(None,), name='decoder_inputs')\n",
    "    enc_out    = build_encoder(in_vocab, max_len, d_model, num_heads, num_layers, dp)(enc_inputs)\n",
    "    dec_out    = build_decoder(tar_vocab, max_len, d_model, num_heads, num_layers, dp)([dec_inputs, enc_out])\n",
    "    outputs    = Dense(tar_vocab, activation='softmax', name='final_output')(dec_out)\n",
    "    return Model(inputs=[enc_inputs, dec_inputs], outputs=outputs, name='TransformerModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49f90a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hdgn5\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:216: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"TransformerModel\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"TransformerModel\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ TransformerEncoder  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">6,339,840</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ TransformerDecoder  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">10,584,320</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ TransformerEncod… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">237</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">60,909</span> │ TransformerDecod… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ TransformerEncoder  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m6,339,840\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ TransformerDecoder  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │ \u001b[38;5;34m10,584,320\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ TransformerEncod… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m237\u001b[0m) │     \u001b[38;5;34m60,909\u001b[0m │ TransformerDecod… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,985,069</span> (64.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,985,069\u001b[0m (64.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,985,069</span> (64.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,985,069\u001b[0m (64.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transformer = build_transformer(\n",
    "    input_vocab_size, target_vocab_size,\n",
    "    max_len, d_model=256, num_heads=4,\n",
    "    num_layers=4, dp=0.1\n",
    ")\n",
    "transformer.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy'\n",
    ")\n",
    "transformer.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
