{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de7be645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¦ TensorFlow ve Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Embedding, Dropout, LayerNormalization,\n",
    "    MultiHeadAttention, Add, Lambda\n",
    ")\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# ğŸ§ª SÄ±ralÄ± bloklar iÃ§in\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "# ğŸ§  Tokenizer ve padding iÃ§in\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# ğŸ“Š Veri iÅŸleme (eÄŸer kullanÄ±yorsan)\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efbdda9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Merhaba</td>\n",
       "      <td>Merhaba, size nasÄ±l yardÄ±mcÄ± olabilirim?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NasÄ±lsÄ±n?</td>\n",
       "      <td>Ä°yiyim, teÅŸekkÃ¼r ederim. Siz nasÄ±lsÄ±nÄ±z?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdÄ±n ne?</td>\n",
       "      <td>Ben bir yapay zekÃ¢ asistanÄ±yÄ±m. AdÄ±m yok ama y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KaÃ§ yaÅŸÄ±ndasÄ±n?</td>\n",
       "      <td>Benim yaÅŸÄ±m yok, dijitalim!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BugÃ¼n gÃ¼nlerden ne?</td>\n",
       "      <td>Maalesef tarih bilgim yok, ama sistem saatinde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 input                                             output\n",
       "0              Merhaba           Merhaba, size nasÄ±l yardÄ±mcÄ± olabilirim?\n",
       "1            NasÄ±lsÄ±n?           Ä°yiyim, teÅŸekkÃ¼r ederim. Siz nasÄ±lsÄ±nÄ±z?\n",
       "2             AdÄ±n ne?  Ben bir yapay zekÃ¢ asistanÄ±yÄ±m. AdÄ±m yok ama y...\n",
       "3      KaÃ§ yaÅŸÄ±ndasÄ±n?                        Benim yaÅŸÄ±m yok, dijitalim!\n",
       "4  BugÃ¼n gÃ¼nlerden ne?  Maalesef tarih bilgim yok, ama sistem saatinde..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Ã¶rnek_set.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ee67491",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = df['input'].astype(str).to_list()\n",
    "target_texts = df['output'].astype(str).to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4500747",
   "metadata": {},
   "source": [
    "### TOKENÄ°ZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba595570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BaÅŸlangÄ±Ã§ ve bitiÅŸ token'larÄ± ekle\n",
    "target_texts_in  = ['<start> ' + t for t in target_texts]\n",
    "target_texts_out = [t + ' <end>'    for t in target_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08926a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokenizer  = Tokenizer(oov_token='<OOV>')\n",
    "input_tokenizer.fit_on_texts(input_texts)\n",
    "target_tokenizer = Tokenizer(oov_token='<OOV>')\n",
    "target_tokenizer.fit_on_texts(target_texts_in + target_texts_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "593a0dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seqs  = input_tokenizer.texts_to_sequences(input_texts)\n",
    "decoder_in  = target_tokenizer.texts_to_sequences(target_texts_in)\n",
    "decoder_out = target_tokenizer.texts_to_sequences(target_texts_out)\n",
    "\n",
    "max_len_input  = max(len(seq) for seq in input_seqs)\n",
    "max_len_output = max(len(seq) for seq in decoder_in + decoder_out)\n",
    "max_len        = max(max_len_input, max_len_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f9590b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "237\n"
     ]
    }
   ],
   "source": [
    "encoder_input  = pad_sequences(input_seqs, padding='post', maxlen=max_len)\n",
    "decoder_input  = pad_sequences(decoder_in,   padding='post', maxlen=max_len)\n",
    "decoder_target = pad_sequences(decoder_out,  padding='post', maxlen=max_len)\n",
    "\n",
    "input_vocab_size  = len(input_tokenizer.word_index) + 1\n",
    "target_vocab_size = len(target_tokenizer.word_index) + 1\n",
    "\n",
    "print(input_vocab_size)\n",
    "print(target_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c64b45",
   "metadata": {},
   "source": [
    "#### ğŸ“Œ 2. position_encoding() -- ğŸ“Œ 3. token_and_position_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "987b183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self, max_len, d_model, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        angle_rads = self._get_angles(\n",
    "            np.arange(max_len)[:, np.newaxis],\n",
    "            np.arange(d_model)[np.newaxis, :],\n",
    "            d_model\n",
    "        )\n",
    "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "        self.pos_encoding = tf.constant(angle_rads[np.newaxis, ...], dtype=tf.float32)\n",
    "    def _get_angles(self, pos, i, d_model):\n",
    "        return pos / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    def call(self, x):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        return x + self.pos_encoding[:, :seq_len, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e782212d",
   "metadata": {},
   "source": [
    "### ğŸ“Œ 4. add_and_norm() --- ğŸ“Œ 5. feed_forward_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf88fbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_and_norm(x, sublayer, dp=0.1):\n",
    "    out = Dropout(dp)(sublayer)\n",
    "    out = layers.Add()([x, out])\n",
    "    return LayerNormalization(epsilon=1e-6)(out)\n",
    "\n",
    "def feed_forward_network(d_model):\n",
    "    # Removed explicit name to avoid duplicate naming errors\n",
    "    return Sequential([\n",
    "        layers.Dense(d_model * 4, activation='relu'),\n",
    "        Dropout(0.1),\n",
    "        layers.Dense(d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce73b6d",
   "metadata": {},
   "source": [
    "-------\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb7a65d",
   "metadata": {},
   "source": [
    "### âœ…  Mask Fonksiyonu â€“ Toplu Kod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3123b600",
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_mask_layer = Lambda(\n",
    "    lambda seq: tf.cast(tf.math.equal(seq, 0), tf.float32)[:, tf.newaxis, tf.newaxis, :],\n",
    "    name=\"padding_mask\"\n",
    ")\n",
    "\n",
    "def combined_mask_layer(seq):\n",
    "    seq_len = tf.shape(seq)[1]\n",
    "    pad     = tf.cast(tf.math.equal(seq, 0), tf.float32)[:, tf.newaxis, tf.newaxis, :]\n",
    "    look    = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    look    = look[tf.newaxis, tf.newaxis, :, :]\n",
    "    return tf.maximum(pad, look)\n",
    "\n",
    "combined_mask_layer = Lambda(combined_mask_layer, name=\"combined_mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ae1524",
   "metadata": {},
   "source": [
    "-----\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cb5591",
   "metadata": {},
   "source": [
    "### ğŸ“Œ 6. encoder_block()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a261473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_block(x, d_model, num_heads, dp, mask):\n",
    "    attn = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(x, x, attention_mask=mask)\n",
    "    x1   = add_and_norm(x, attn, dp)\n",
    "    ffn  = feed_forward_network(d_model)(x1)\n",
    "    return add_and_norm(x1, ffn, dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c820c9",
   "metadata": {},
   "source": [
    "### ğŸ“Œ 7. decoder_block()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe7cd150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(x, enc_out, d_model, num_heads, dp, look_mask, pad_mask):\n",
    "    attn1 = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(x, x, attention_mask=look_mask)\n",
    "    x1    = add_and_norm(x, attn1, dp)\n",
    "    attn2 = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(x1, enc_out, attention_mask=pad_mask)\n",
    "    x2    = add_and_norm(x1, attn2, dp)\n",
    "    ffn   = feed_forward_network(d_model)(x2)\n",
    "    return add_and_norm(x2, ffn, dp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193aaf45",
   "metadata": {},
   "source": [
    "### ğŸ“Œ 8. build_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4467017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder(vocab_size, max_len, d_model, num_heads, num_layers, dp):\n",
    "    inp  = Input(shape=(None,), name='encoder_input')\n",
    "    mask = padding_mask_layer(inp)\n",
    "    x    = Embedding(vocab_size, d_model)(inp)\n",
    "    x    = PositionalEncoding(max_len, d_model)(x)\n",
    "    for _ in range(num_layers):\n",
    "        x = encoder_block(x, d_model, num_heads, dp, mask)\n",
    "    return Model(inputs=inp, outputs=x, name='TransformerEncoder')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f736116f",
   "metadata": {},
   "source": [
    "### ğŸ“Œ 9. build_decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96e70a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decoder(vocab_size, max_len, d_model, num_heads, num_layers, dp):\n",
    "    dec_in  = Input(shape=(None,), name='decoder_input')\n",
    "    enc_out = Input(shape=(None, d_model), name='encoder_output')\n",
    "    look    = combined_mask_layer(dec_in)\n",
    "    pad     = padding_mask_layer(dec_in)\n",
    "    x       = Embedding(vocab_size, d_model)(dec_in)\n",
    "    x       = PositionalEncoding(max_len, d_model)(x)\n",
    "    for _ in range(num_layers):\n",
    "        x = decoder_block(x, enc_out, d_model, num_heads, dp, look, pad)\n",
    "    return Model(inputs=[dec_in, enc_out], outputs=x, name='TransformerDecoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7d9919",
   "metadata": {},
   "source": [
    "### ğŸ“Œ 10. build_transformer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db85aa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transformer(in_vocab, tar_vocab, max_len, d_model, num_heads, num_layers, dp):\n",
    "    enc_inputs = Input(shape=(None,), name='encoder_inputs')\n",
    "    dec_inputs = Input(shape=(None,), name='decoder_inputs')\n",
    "    enc_out    = build_encoder(in_vocab, max_len, d_model, num_heads, num_layers, dp)(enc_inputs)\n",
    "    dec_out    = build_decoder(tar_vocab, max_len, d_model, num_heads, num_layers, dp)([dec_inputs, enc_out])\n",
    "    outputs    = Dense(tar_vocab, activation='softmax', name='final_output')(dec_out)\n",
    "    return Model(inputs=[enc_inputs, dec_inputs], outputs=outputs, name='TransformerModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49f90a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hdgn5\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:216: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"TransformerModel\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"TransformerModel\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ encoder_inputs      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_inputs      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ TransformerEncoder  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">6,339,840</span> â”‚ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ TransformerDecoder  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">10,584,320</span> â”‚ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ TransformerEncodâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ final_output        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">237</span>) â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">60,909</span> â”‚ TransformerDecodâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ encoder_inputs      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_inputs      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ TransformerEncoder  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) â”‚  \u001b[38;5;34m6,339,840\u001b[0m â”‚ encoder_inputs[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ TransformerDecoder  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) â”‚ \u001b[38;5;34m10,584,320\u001b[0m â”‚ decoder_inputs[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ TransformerEncodâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ final_output        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m237\u001b[0m) â”‚     \u001b[38;5;34m60,909\u001b[0m â”‚ TransformerDecodâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,985,069</span> (64.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,985,069\u001b[0m (64.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,985,069</span> (64.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,985,069\u001b[0m (64.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transformer = build_transformer(\n",
    "    input_vocab_size, target_vocab_size,\n",
    "    max_len, d_model=256, num_heads=4,\n",
    "    num_layers=4, dp=0.1\n",
    ")\n",
    "transformer.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy'\n",
    ")\n",
    "transformer.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
